<æ•°å­¦ä¹‹ç¾>ï¼š
    æ¨¡å‹ä¸å¹³æ»‘ï¼š
        å³æœ‰å¾ˆå¤šé¢„æµ‹çš„æ¡ä»¶æ¦‚ç‡ä¸ºé›¶
        
        å¦‚ï¼š
            æ±‰å­—200000ä¸ªï¼Œå³ä¾¿ç”¨å…¨éƒ¨äº’è”ç½‘çš„èµ„æ–™å»è®­ç»ƒï¼Œä¾ç„¶æœ‰å¾ˆå¤šæœªæ›¾å‡ºç°çš„è¯ï¼Œè¿™å°±å¯¼è‡´ä¼šæœ‰å¾ˆå¤šé¢„æµ‹çš„æ¦‚ç‡ä¸ºé›¶ã€‚å…¶å®çœŸå®å¹¶ä¸æ˜¯é›¶ï¼Œè¿™å°±æ˜¯ä¸å¹³æ»‘ã€‚
        
            å¯¹äºæ²¡å‡ºç°çš„äº‹ä»¶ï¼Œæˆ‘ä¸èƒ½è®¤ä¸ºå®ƒçš„æ¦‚ç‡å°±æ˜¯é›¶ã€‚å¦‚ä½•è§£å†³æ ·æœ¬çš„è¿™ä¸ªé—®é¢˜ï¼Œè¿›ä¸€æ­¥æ›´å¥½çš„è®­ç»ƒå‘¢ï¼Ÿ
                æˆ‘ä»¬å¯¹ä¸å¯ä¿¡çš„ç»Ÿè®¡æ•°æ®æ‰“æŠ˜æ‰£ï¼ŒåŒæ—¶å°†æŠ˜æ‰£å‡ºæ¥çš„é‚£ä¸€å°éƒ¨åˆ†æ¦‚ç‡ç»™äºˆæœªå‡ºç°ä½†æ¦‚ç‡ä¸å¯èƒ½ä¸ºé›¶çš„å°æ¦‚ç‡äº‹ä»¶ã€‚è¶Šæ˜¯ä¸å¯ä¿¡æŠ˜æ‰£å°±è¶Šå¤šã€‚â€”â€”ï¼ˆGood-Turing Estimateï¼‰
    
    åˆ†è¯ï¼š
        è¯çš„åˆ†èŠ‚ç¬¦ï¼ˆDelimitï¼‰
        
        ä¸€å¼€å§‹ç”¨äºä¸­é—´æ— ç©ºæ ¼çš„ä¸œäºšæ–‡å­—ï¼Œåæ¥ä¹Ÿåº”ç”¨åˆ°äº†è‹±æ–‡çš„æ‰‹å†™è¯†åˆ«ä¸­ï¼ˆæ‰‹å†™è¯†åˆ«æœ‰çš„æ˜¯è¿ç¬”ï¼Œå¿…é¡»åˆ†è¯ï¼‰

        æœ€æ—©  æ¢å—å…ƒâ€”â€”æŸ¥å­—å…¸ï¼Œæœ€é•¿åŒ¹é…  ç¼ºç‚¹ï¼šåŒ—äº¬å¤§å­¦ç”Ÿ--->  "åŒ—äº¬å¤§å­¦" + "ç”Ÿ"
        äºŒã€ ç‹æ™“é¾™åšå£«   æœ€å°‘æ¬¡æ•°çš„åˆ†è¯ç†è®º      ---->ä¸èƒ½è§£å†³äºŒä¹‰æ€§é—®é¢˜    åº”"å‘å±•ä¸­å›½å®¶"--->"å‘å±•"+"ä¸­"+"å›½å®¶"   è€Œéï¼š "å‘å±•"+ "ä¸­å›½" + "å®¶"
        ä¸‰ã€éƒ­è¿›ï¼šç»Ÿè®¡è¯­è¨€æ¨¡å‹   è®¡ç®—æ¦‚ç‡æœ€å¤§çš„åˆ†æ³•ï¼ˆç»´ç‰¹æ¯”ç®—æ³•ï¼ˆåŠ¨æ€è§„åˆ’ï¼‰ï¼‰   ç¼ºç‚¹ï¼šä¾èµ–å¤§ä¼—çš„çœ‹æ³•ï¼Œåœ¨ç‰¹å®šæƒ…å†µä¸‹æ˜¯é”™çš„   ä¼˜ç‚¹ï¼šå·²ç»æ¯”äººå·¥æ ‡è®°å‡†ç¡®äº†

        è¯çš„é¢—ç²’åº¦åˆ’åˆ†ï¼š
            æœ‰ä¸¤æ´¾è¯­è¨€å­¦å®¶ï¼š
                1. æ¸…åå¤§å­¦  æ•´ä½“æ˜¯ä¸€ä¸ªè¯
                2.åº”è¯¥åˆ†ä¸º  "æ¸…å" å’Œ "å¤§å­¦" ä¸¤ä¸ªè¯

            ä½†å„æœ‰å¥½å¤„ï¼Œå¦‚ï¼š
                        åœ¨æœºå™¨ç¿»è¯‘ä¸­ï¼š "è”æƒ³å…¬å¸"è§†ä½œä¸€ä¸ªè¯æ¯”è¾ƒå¥½
                        åœ¨æœç´¢å¼•æ“ä¸­ï¼Œè§†ä½œä¸¤ä¸ªè¯ï¼Œå¦åˆ™ï¼Œç”¨æˆ·æœç´¢"æ¸…å"æœä¸å‡ºæ¸…åå¤§å­¦
            
            æ‰€ä»¥ç»¼åˆä¸€ä¸‹:é‡‡ç”¨ä¸€ä¸ªåˆ†è¯å™¨åŒæ—¶æ”¯æŒä¸åŒå±‚æ¬¡çš„è¯çš„åˆ’åˆ†ã€‚"æ¸…åå¤§å­¦"æ—¢å¯ä»¥è¢«è§†ä½œä¸€ä¸ªæ•´ä½“åˆå¯ä»¥è§†ä½œä¸¤ä¸ªè¯ã€‚
                åˆ†è¯å™¨ï¼š
                    1.åŸºæœ¬è¯è¡¨ï¼šåŸºæœ¬è¯æ¯”è¾ƒç¨³å®šï¼Œåˆ†è¯æ–¹æ³•å·²ç»è§£å†³ï¼Œåªè¦å®šæœŸå¢åŠ ä¸€äº›æ–°è¯å³å¯
                    2.å¤åˆè¯è¡¨

        ä¸­æ–‡åˆ†è¯ä»¥ç»Ÿè®¡è¯­è¨€æ¨¡å‹ä¸ºåŸºç¡€ï¼Œç»è¿‡å‡ åå¹´çš„å‘å±•å’Œå®Œå–„ï¼Œä»Šå¤©åŸºæœ¬ä¸Šå¯ä»¥çœ‹ä½œä¸€ä¸ªå·²ç»è§£å†³çš„é—®é¢˜ã€‚å´å†›è®¤ä¸ºåˆ†è¯æ˜¯ä¸€ä¸ªå·²ç»è§£å†³çš„é—®é¢˜ï¼Œæå‡çš„ç©ºé—´å¾®ä¹å…¶å¾®ã€‚åªè¦é‡‡ç”¨ç»Ÿè®¡è¯­è¨€æ¨¡å‹ï¼Œæ•ˆæœéƒ½å·®ä¸åˆ°å“ªé‡Œå»ã€‚
        å½“ç„¶ä¸åŒçš„äººåšçš„åˆ†è¯å™¨æœ‰å¥½æœ‰åï¼Œè¿™é‡Œé¢çš„å·®åˆ«ä¸»è¦åœ¨äºæ•°æ®çš„ä½¿ç”¨å’Œå·¥ç¨‹å®ç°çš„ç²¾åº¦ã€‚


--------------------------------------------------
ææ°¸ä¹è€å¸ˆ:youtube å‚…é‡Œå¶å˜æ¢
å˜æ¢ï¼š å‘é‡åˆ°æ•°å­—è¡¨æ¢æ˜¯ä¸€ç§æœ€ç®€å•çš„å˜æ¢
    æ ‡å‡†æ­£äº¤åŸºï¼š å‘é‡ç»å¯¹å€¼å”¯ä¸€ï¼Œä¸”äº’ç›¸å‚ç›´

å‚…é‡Œå¶å˜æ¢åˆ†ä¸ºä¸¤ç§ï¼š

    å‚…é‡Œå¶çº§æ•°ä»»ä½•ä¸€ä¸ªå‘¨æœŸæ€§çš„å‡½æ•°fï¼ˆtï¼‰éƒ½å¯ä»¥å˜æ¢æˆä¸€ç³»åˆ—æ­£ï¼ˆä½™ï¼‰å¼¦å‡½æ•°ï¼ˆï¼‰çš„å’Œã€‚

    ä¸åŒé¢‘ç‡ä¿¡å·---> æŒ¯å¹…ã€ç›¸ä½ã€é¢‘ç‡ä¸‰ä¸ªç»´åº¦è¿›è¡Œè¡¨ç¤ºã€‚

å‚…é‡Œå¶å˜æ¢ï¼š
    å°†ä¿¡å·ï¼ˆå³ä¾¿ä¸æ˜¯å‘¨æœŸå‡½æ•°ï¼Œä¹Ÿå¯ä»¥è§†ä½œå‘¨æœŸæ— ç©·å¤§ï¼‰é‡Œçš„æ­£ä½™å¼¦å‡½æ•°æ‘˜å‡ºæ¥ï¼Œä¹Ÿå¯ä»¥æŠŠè¿™äº›æ­£ä½™å¼¦å‡½æ•°è¿˜åŸå›åŸä¿¡å·ï¼ˆå˜æ¢ï¼‰

    åº”ç”¨ï¼š
        1.å£°éŸ³çš„å¤„ç†
            ä½é¢‘ä¿¡å·--->ç”·ç”Ÿ  é«˜é¢‘ä¿¡å·---->å¥³ç”Ÿ è¶…ä½é¢‘ä¿¡å·---->å™ªéŸ³
            ç”·å£°å˜å¥³å£°  ----->å‚…é‡Œå¶å˜æ¢å°†ä½é¢‘è½¬ä¸ºé«˜é¢‘å†åå˜æ¢å›å»ã€‚
            å¥¥å·´é©¬çš„å£°éŸ³ã€æœ¬æ‹‰ç™»çš„å£°éŸ³
        2.å›¾åƒçš„å¤„ç†
            äººåƒï¼šå›¾ç‰‡--->å‚…é‡Œå¶å˜æ¢---->ä½é¢‘ï¼ˆè½®å»“ï¼‰  é«˜é¢‘ï¼ˆç»†èŠ‚ï¼ˆæ–‘ç‚¹ï¼‰ï¼‰ï¼Œå¤„ç†å®Œé«˜é¢‘ä¿¡å·è¿˜åŸå›å»ï¼ˆç£¨çš®ç¾è‰³çš„åŸç†ï¼‰

æƒ³æ³•ï¼šå¯¹æ–°é—»åšå‚…é‡Œå¶å˜æ¢å¯ä¸å¯èƒ½åˆ†å¼€çœŸç›¸å’Œæƒ…ç»ªï¼Ÿ
---------------------------------------------------------------------------

self-attention
    å›¾ï¼šå°è±¡ç¬”è®°ï¼šself-attention

    (å¼ ä¿Šæ—åšå£«ï¼šå¼ ä¿Šæ—-æ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶(2017ç‰ˆ)https://blog.csdn.net/malefactor/article/details/78767781

    å›¾1å½¢è±¡åŒ–å±•ç¤ºäº†äººç±»åœ¨çœ‹åˆ°ä¸€å‰¯å›¾åƒæ—¶æ˜¯å¦‚ä½•é«˜æ•ˆåˆ†é…æœ‰é™çš„æ³¨æ„åŠ›èµ„æºçš„ï¼Œå…¶ä¸­çº¢è‰²åŒºåŸŸè¡¨æ˜è§†è§‰ç³»ç»Ÿæ›´å…³æ³¨çš„ç›®æ ‡ï¼Œå¾ˆæ˜æ˜¾å¯¹äºå›¾1æ‰€ç¤ºçš„åœºæ™¯ï¼Œäººä»¬ä¼šæŠŠæ³¨æ„åŠ›æ›´å¤šæŠ•å…¥åˆ°äººçš„è„¸éƒ¨ï¼Œæ–‡æœ¬çš„æ ‡é¢˜ä»¥åŠæ–‡ç« é¦–å¥ç­‰ä½ç½®ã€‚

    Encoder-Decoderæ¡†æ¶ï¼ˆseq2seqï¼‰
        /*/ä¸€èˆ¬è€Œè¨€ï¼Œæ–‡æœ¬å¤„ç†å’Œè¯­éŸ³è¯†åˆ«çš„Encoderéƒ¨åˆ†é€šå¸¸é‡‡ç”¨RNNæ¨¡å‹ï¼Œå›¾åƒå¤„ç†çš„Encoderä¸€èˆ¬é‡‡ç”¨CNNæ¨¡å‹ã€‚
        Encoder-Decoderæ¡†æ¶æ˜¯æ²¡æœ‰ä½“ç°å‡ºâ€œæ³¨æ„åŠ›æ¨¡å‹â€çš„ï¼Œæ‰€ä»¥å¯ä»¥æŠŠå®ƒçœ‹ä½œæ˜¯æ³¨æ„åŠ›ä¸é›†ä¸­çš„åˆ†å¿ƒæ¨¡å‹ã€‚

        å¤§å¤šæ•°æ·±åº¦å­¦ä¹ æ³¨æ„åŠ›æ¨¡å‹é™„ç€åœ¨Encoder-Decoderæ¡†æ¶ä¸‹ï¼Œå½“ç„¶ï¼Œå…¶å®æ³¨æ„åŠ›æ¨¡å‹å¯ä»¥çœ‹ä½œä¸€ç§é€šç”¨çš„æ€æƒ³ï¼Œæœ¬èº«å¹¶ä¸ä¾èµ–äºç‰¹å®šæ¡†æ¶ï¼Œè¿™ç‚¹éœ€è¦æ³¨æ„ã€‚

        å›¾2æ˜¯æ–‡æœ¬å¤„ç†é¢†åŸŸé‡Œå¸¸ç”¨çš„Encoder-Decoderæ¡†æ¶æœ€æŠ½è±¡çš„ä¸€ç§è¡¨ç¤ºã€‚

        Sourceå’ŒTargetå¯ä»¥æ˜¯åŒä¸€ç§è¯­è¨€ï¼Œä¹Ÿå¯ä»¥æ˜¯ä¸¤ç§ä¸åŒçš„è¯­è¨€ã€‚è€ŒSourceå’ŒTargetåˆ†åˆ«ç”±å„è‡ªçš„å•è¯åºåˆ—æ„æˆï¼š
            Encoderé¡¾åæ€ä¹‰å°±æ˜¯å¯¹è¾“å…¥å¥å­Sourceè¿›è¡Œç¼–ç ï¼Œå°†è¾“å…¥å¥å­é€šè¿‡éçº¿æ€§å˜æ¢è½¬åŒ–ä¸ºä¸­é—´è¯­ä¹‰è¡¨ç¤ºCï¼š

            å¯¹äºè§£ç å™¨Decoderæ¥è¯´ï¼Œå…¶ä»»åŠ¡æ˜¯æ ¹æ®å¥å­Sourceçš„ä¸­é—´è¯­ä¹‰è¡¨ç¤ºCå’Œä¹‹å‰å·²ç»ç”Ÿæˆçš„å†å²ä¿¡æ¯y1,y2......yi-1æ¥ç”Ÿæˆiæ—¶åˆ»è¦ç”Ÿæˆçš„å•è¯yiï¼š
        
        å¦‚æœSourceæ˜¯ä¸€ç¯‡æ–‡ç« ï¼ŒTargetæ˜¯æ¦‚æ‹¬æ€§çš„å‡ å¥æè¿°è¯­å¥ï¼Œé‚£ä¹ˆè¿™æ˜¯æ–‡æœ¬æ‘˜è¦çš„Encoder-Decoderæ¡†æ¶ï¼›å¦‚æœSourceæ˜¯ä¸€å¥é—®å¥ï¼ŒTargetæ˜¯ä¸€å¥å›ç­”ï¼Œé‚£ä¹ˆè¿™æ˜¯é—®ç­”ç³»ç»Ÿæˆ–è€…å¯¹è¯æœºå™¨äººçš„Encoder-Decoderæ¡†æ¶ã€‚

        Encoder-Decoderæ¡†æ¶ä¸ä»…ä»…åœ¨æ–‡æœ¬é¢†åŸŸå¹¿æ³›ä½¿ç”¨ï¼Œåœ¨è¯­éŸ³è¯†åˆ«ã€å›¾åƒå¤„ç†ç­‰é¢†åŸŸä¹Ÿç»å¸¸ä½¿ç”¨ã€‚æ¯”å¦‚å¯¹äºè¯­éŸ³è¯†åˆ«æ¥è¯´ï¼Œå›¾2æ‰€ç¤ºçš„æ¡†æ¶å®Œå…¨é€‚ç”¨ï¼ŒåŒºåˆ«æ— éæ˜¯Encoderéƒ¨åˆ†çš„è¾“å…¥æ˜¯è¯­éŸ³æµï¼Œè¾“å‡ºæ˜¯å¯¹åº”çš„æ–‡æœ¬ä¿¡æ¯ï¼›è€Œå¯¹äºâ€œå›¾åƒæè¿°â€ä»»åŠ¡æ¥è¯´ï¼ŒEncoderéƒ¨åˆ†çš„è¾“å…¥æ˜¯ä¸€å‰¯å›¾ç‰‡ï¼ŒDecoderçš„è¾“å‡ºæ˜¯èƒ½å¤Ÿæè¿°å›¾ç‰‡è¯­ä¹‰å†…å®¹çš„ä¸€å¥æè¿°è¯­ã€‚

Attentionæ¨¡å‹ï¼š
    soft attentionï¼šï¼ˆæœ€å¸¸è§çš„attentionæ¨¡å‹ï¼‰

        Encoder-Decoderæ¡†æ¶æ˜¯æ²¡æœ‰ä½“ç°å‡ºâ€œæ³¨æ„åŠ›æ¨¡å‹â€çš„ï¼Œæ‰€ä»¥å¯ä»¥æŠŠå®ƒçœ‹ä½œæ˜¯æ³¨æ„åŠ›ä¸é›†ä¸­çš„åˆ†å¿ƒæ¨¡å‹ã€‚

        ä¸ºä»€ä¹ˆè¯´encoder-decoderæ¨¡å‹æ˜¯â€œåˆ†å¿ƒæ¨¡å‹â€å‘¢ï¼Ÿ
            è§å›¾ä¸‰
            å…¶ä¸­fæ˜¯Decoderçš„éçº¿æ€§å˜æ¢å‡½æ•°ã€‚ä»è¿™é‡Œå¯ä»¥çœ‹å‡ºï¼Œåœ¨ç”Ÿæˆç›®æ ‡å¥å­çš„å•è¯æ—¶ï¼Œä¸è®ºç”Ÿæˆå“ªä¸ªå•è¯ï¼Œå®ƒä»¬ä½¿ç”¨çš„è¾“å…¥å¥å­Sourceçš„è¯­ä¹‰ç¼–ç Céƒ½æ˜¯ä¸€æ ·çš„ï¼Œæ²¡æœ‰ä»»ä½•åŒºåˆ«ã€‚

            è€Œè¯­ä¹‰ç¼–ç Cæ˜¯ç”±å¥å­Sourceçš„æ¯ä¸ªå•è¯ç»è¿‡Encoder ç¼–ç äº§ç”Ÿçš„ï¼Œè¿™æ„å‘³ç€ä¸è®ºæ˜¯ç”Ÿæˆå“ªä¸ªå•è¯ï¼Œy1,y2è¿˜æ˜¯y3ï¼Œå…¶å®å¥å­Sourceä¸­ä»»æ„å•è¯å¯¹ç”ŸæˆæŸä¸ªç›®æ ‡å•è¯yiæ¥è¯´å½±å“åŠ›éƒ½æ˜¯ç›¸åŒçš„ï¼Œè¿™æ˜¯ä¸ºä½•è¯´è¿™ä¸ªæ¨¡å‹æ²¡æœ‰ä½“ç°å‡ºæ³¨æ„åŠ›çš„ç¼˜ç”±ã€‚è¿™ç±»ä¼¼äºäººç±»çœ‹åˆ°çœ¼å‰çš„ç”»é¢ï¼Œä½†æ˜¯çœ¼ä¸­å´æ²¡æœ‰æ³¨æ„ç„¦ç‚¹ä¸€æ ·ã€‚

            å›¾å››
            ç†è§£Attentionæ¨¡å‹çš„å…³é”®å°±æ˜¯è¿™é‡Œï¼Œå³ç”±å›ºå®šçš„ä¸­é—´è¯­ä¹‰è¡¨ç¤ºCæ¢æˆäº†æ ¹æ®å½“å‰è¾“å‡ºå•è¯æ¥è°ƒæ•´æˆåŠ å…¥æ³¨æ„åŠ›æ¨¡å‹çš„å˜åŒ–çš„C1ã€C2ã€C3ã€‚å¢åŠ äº†æ³¨æ„åŠ›æ¨¡å‹çš„Encoder-Decoderæ¡†æ¶ç†è§£èµ·æ¥å¦‚å›¾3æ‰€ç¤º


            å…¶ä¸­ï¼Œf2å‡½æ•°ä»£è¡¨Encoderå¯¹è¾“å…¥è‹±æ–‡å•è¯çš„æŸç§å˜æ¢å‡½æ•°ï¼Œæ¯”å¦‚å¦‚æœEncoderæ˜¯ç”¨çš„RNNæ¨¡å‹çš„è¯ï¼Œè¿™ä¸ªf2å‡½æ•°çš„ç»“æœå¾€å¾€æ˜¯æŸä¸ªæ—¶åˆ»è¾“å…¥Xiåéšå±‚èŠ‚ç‚¹çš„çŠ¶æ€å€¼ï¼›gä»£è¡¨Encoderæ ¹æ®å•è¯çš„ä¸­é—´è¡¨ç¤ºåˆæˆæ•´ä¸ªå¥å­ä¸­é—´è¯­ä¹‰è¡¨ç¤ºçš„å˜æ¢å‡½æ•°ï¼Œä¸€èˆ¬çš„åšæ³•ä¸­ï¼Œgå‡½æ•°å°±æ˜¯å¯¹æ„æˆå…ƒç´ åŠ æƒæ±‚å’Œï¼Œå³ä¸‹åˆ—å…¬å¼ï¼š
            å›¾äº”



-------------------------------------------------------------------
çŸ¥è¯†è’¸é¦ï¼šå°†å¤æ‚çš„modelå‹ç¼©ä¸ºç®€å•çš„modelï¼ˆå°æ¨¡å‹è®­ç»ƒéå¸¸å¿«ï¼‰ï¼Œä¸”ç²¾åº¦å‡ ä¹æ²¡æŸå¤±
    1.è®­ç»ƒå¥½è€å¸ˆæ¨¡å‹
    2.

    hard targetï¼š[0, 1, 0, 0, 1]

    soft target:[0.1, 0.2, 0.6, 0.5, 0]


    å­¦ç”Ÿæ¨¡å‹å’Œè€å¸ˆæ¨¡å‹ç»“æ„ä¸€æ‘¸ä¸€æ ·ï¼Œå¦‚æœå¤šä¸ªè€å¸ˆåˆ†åˆ«ä¼šè¯­æ–‡ã€æ•°å­¦ï¼Œå­¦ç”Ÿä¼šæ›´å‰å®³ï¼Œ
        è€å¸ˆæ¨¡å‹å¦‚æœå¤ªå·®ï¼Œç›¸å½“äºå¼•å…¥å™ªéŸ³
        å¦‚æœè€å¸ˆå’Œå­¦ç”Ÿå·®å¼‚å¤ªå°ï¼Œå­¦ç”Ÿå°±æ²¡åŠæ³•å­¦å¤ªå¤šä¸œè¥¿ã€‚(å­¦ç”Ÿå’Œè€å¸ˆè¾¾åˆ°ä¸åŒçš„å±€éƒ¨æœ€ä¼˜)

        å¦‚ä½•è¡¡é‡å·®å¼‚å¤§å°ï¼Ÿ
            è€å¸ˆæ¨¡å‹æ—¶é—´ç¦»å¾—è¿‘ï¼Œå·®å¼‚å°ï¼Œç¦»å¾—è¿œï¼Œå‚æ•°å·®å¼‚å¤§
            æ¯ä¸ªæ ·æœ¬çš„è€å¸ˆä¿¡å·éƒ½æ¥è‡ªäºä¸åŒçš„å†å²æ—¶åˆ»ï¼Œç›¸å½“äºåƒå¤šä¸ªå±€éƒ¨æœ€ä¼˜åŒæ—¶å­¦ä¹ 

    é•¿å‘¨æœŸè€å¸ˆæ˜¯åœ¨æŸä¸€ä¸ª






---------------------------------------------------------------------------------------------------------------------------------------------------------------
æèˆªNSRè®ºæ–‡ï¼šæ·±åº¦å­¦ä¹ NLPçš„ç°æœ‰ä¼˜åŠ¿ä¸æœªæ¥æŒ‘æˆ˜
    NLPè‹¥åˆ’åˆ†ä¸º5ä¸ªä»»åŠ¡ï¼šåˆ†ç±»ã€åŒ¹é…ï¼ˆmatchingï¼‰ã€ç¿»è¯‘ã€ç»“æ„åŒ–é¢„æµ‹ï¼ˆstructured prediction:named entity recognitionï¼‰ã€ä¸åºè´¯å†³ç­–è¿‡ç¨‹ã€‚æ·±åº¦å­¦ä¹ åœ¨å‰å››ä¸ªçš„ä»»åŠ¡çš„ç²¾ç¡®åº¦å‡å·²è¶…è¿‡æœºå™¨å­¦ä¹ ã€‚
        classificationï¼ˆå¦‚sentiment classification, CNN:86%  SVM:79.4%  å·®6%ï¼‰
        matchingï¼ˆquestion answeringï¼Œ CNN, p@1 ï¼š49.6%ï¼Œ MLP p@1ï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰ï¼š36.1%ï¼Œ å·®13%ï¼‰
        translation(NMT, BLEU:39.0, SMT,BLEU:37.0, å·®2)
        structured prediction:(DL acc:91.8%, ML acc:90.7%, å·®1%)

    æ·±åº¦å­¦ä¹ çš„æŒ‘æˆ˜ï¼š no good at indference and decision making 

    ç­‰ï¼Œæœªå®Œå¾…ç»­ã€‚ã€‚ã€‚ã€‚https://www.jiqizhixin.com/articles/2017-10-04-5


            


--------------------------------------------------------------------------
æ·±åº¦å­¦ä¹ åœ¨æƒ…æ„Ÿåˆ†æä¸­çš„åº”ç”¨çš„ç ”ç©¶ç°çŠ¶ï¼Ÿ  çŸ¥ä¹
zhihu.com/question/33985819
    æƒ…æ„Ÿåˆ†ææœ¬è´¨ä¸Šæ˜¯æ–‡æœ¬åˆ†ç±»ï¼Œå¾ˆå¤šæœ€æ–°çš„æ–‡æœ¬åˆ†ç±»æŠ€æœ¯å¯ä»¥åº”ç”¨åˆ°SAã€‚
        è§å›ç­”ï¼š
            å³ä¾¿ä½ æ‰¾ä¸åˆ°æ·±åº¦å­¦ä¹ åœ¨SAä¸Šçš„è®ºæ–‡ï¼Œæ–‡æœ¬åˆ†ç±»æ€»æ˜¯å¯ä»¥çš„å“‡ã€‚â€”â€”éå…¸å‹CSåšå£« ä¸œå—å¤§å­¦ è®¡ç®—æœºç§‘å­¦åšå£«åœ¨è¯»

            çœ‹è¿‡ä¸å°‘å…ˆå‘åœ¨æ–‡æœ¬åˆ†ç±»ä¸Šçš„è®ºæ–‡ç„¶åç¨å¾®æ”¹æ”¹å‘åˆ°é¡¶ä¼šä¸Šçš„paperï¼Œå¦‚emnlp   â€”â€”ä¸æ€èœ€



--------------------------------------------------------------------------------------
---------------------------------------------------------------------------
å‡†ç¡®ç‡Pã€å¬å›ç‡Rã€F1 å€¼ï¼š
    å®šä¹‰ï¼š
        å‡†ç¡®ç‡ï¼ˆPrecisionï¼‰ï¼šP=TP/(TP+FP)ã€‚é€šä¿—åœ°è®²ï¼Œå°±æ˜¯é¢„æµ‹æ­£ç¡®çš„æ­£ä¾‹æ•°æ®å é¢„æµ‹ä¸ºæ­£ä¾‹æ•°æ®çš„æ¯”ä¾‹ã€‚
        å¬å›ç‡ï¼ˆRecallï¼‰ï¼šR=TP/(TP+FN)ã€‚é€šä¿—åœ°è®²ï¼Œå°±æ˜¯é¢„æµ‹ä¸ºæ­£ä¾‹çš„æ•°æ®å å®é™…ä¸ºæ­£ä¾‹æ•°æ®çš„æ¯”ä¾‹
        F1å€¼ï¼ˆF scoreï¼‰ F1 = 2/ï¼ˆ1/P + 1/Rï¼‰ = ï¼ˆ2*P*Rï¼‰/ï¼ˆP+Rï¼‰
    
    F1å€¼å¾—æ„ä¹‰ï¼š
        å®é™…ç”Ÿäº§ç”Ÿæ´»ä¸­ï¼Œå•çº¯çš„è¿½æ±‚å‡†ç¡®ç‡å’Œå¬å›ç‡éƒ½æ²¡æœ‰æ„ä¹‰ï¼Œåªæœ‰äºŒè€…çš†ä¸é”™æ‰å¯èƒ½å®é™…åº”ç”¨ï¼Œè¿™å°±æ˜¯F1å€¼å¾—ä½œç”¨ã€‚    

ROCã€AUC
    å®šä¹‰ï¼š
        TPR=TP/(TP+FN)=TP/actual positives
        FPR=FP/(FP+TN)=FP/actual negatives
        ROCæ˜¯ç”±ç‚¹ï¼ˆTPR,FPRï¼‰ç»„æˆçš„æ›²çº¿ï¼ŒAUCå°±æ˜¯ROCçš„é¢ç§¯ã€‚AUCè¶Šå¤§è¶Šå¥½ã€‚
        ä¸€èˆ¬æ¥è¯´ï¼Œå¦‚æœROCæ˜¯å…‰æ»‘çš„ï¼Œé‚£ä¹ˆåŸºæœ¬å¯ä»¥åˆ¤æ–­æ²¡æœ‰å¤ªå¤§çš„overfitting



-------------------------------------------------------------------------------------------------------------------
http://sofasofa.io/forum_main_post.php?postid=1001112
F1 scoreæ˜¯ä¸€ä¸ªç”¨æ¥è¯„ä»·äºŒå…ƒåˆ†ç±»å™¨çš„åº¦é‡ã€‚å…ˆå›é¡¾ä¸€ä¸‹å®ƒçš„è®¡ç®—å…¬å¼ï¼š

F1=21recall+1precision=2recallÃ—precisionrecall+precision



F1æ˜¯é’ˆå¯¹äºŒå…ƒåˆ†ç±»çš„ï¼Œé‚£å¯¹äºå¤šå…ƒåˆ†ç±»å™¨ï¼Œæœ‰æ²¡æœ‰ç±»ä¼¼F1 scoreçš„åº¦é‡æ–¹æ³•å‘¢ï¼Ÿæœ‰çš„ï¼Œè€Œä¸”è¿˜ä¸æ­¢ä¸€ç§ï¼Œå¸¸ç”¨çš„æœ‰ä¸¤ç§ï¼Œè¿™å°±æ˜¯é¢˜ä¸»æ‰€é—®çš„ä¸¤ç§ï¼Œä¸€ç§å«åšmacro-F1ï¼Œå¦ä¸€ç§å«åšmicro-F1ã€‚



macro-F1(å®è§‚)

å‡è®¾å¯¹äºä¸€ä¸ªå¤šåˆ†ç±»é—®é¢˜ï¼Œæœ‰ä¸‰ä¸ªç±»ï¼Œåˆ†åˆ«è®°ä¸º1ã€2ã€3ï¼Œ

TPiæ˜¯æŒ‡åˆ†ç±»içš„True Positiveï¼›

FPiæ˜¯æŒ‡åˆ†ç±»içš„False Positiveï¼›

TNiæ˜¯æŒ‡åˆ†ç±»içš„True Negativeï¼›

FNiæ˜¯æŒ‡åˆ†ç±»içš„False Negativeã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬åˆ†åˆ«è®¡ç®—æ¯ä¸ªç±»çš„ç²¾åº¦(precision)

precisioni=TPiTPi+FPi

macroç²¾åº¦å°±æ˜¯æ‰€æœ‰ç²¾åº¦çš„å‡å€¼

precisionma=precision1+precision2+precision33

ç±»ä¼¼åœ°ï¼Œæˆ‘ä»¬åˆ†åˆ«è®¡ç®—æ¯ä¸ªç±»çš„å¬å›(recall)

recalli=TPiTPi+FNi

macroå¬å›å°±æ˜¯æ‰€æœ‰å¬å›çš„å‡å€¼

recallma=recall1+recall2+recall33

æœ€åmacro-F1çš„è®¡ç®—å…¬å¼ä¸º

F1,ma=2recallmaÃ—precisionmarecallma+precisionma



micro-F1

å‡è®¾å¯¹äºä¸€ä¸ªå¤šåˆ†ç±»é—®é¢˜ï¼Œæœ‰ä¸‰ä¸ªç±»ï¼Œåˆ†åˆ«è®°ä¸º1ã€2ã€3ï¼Œ

TPiæ˜¯æŒ‡åˆ†ç±»içš„True Positiveï¼›

FPiæ˜¯æŒ‡åˆ†ç±»içš„False Positiveï¼›

TNiæ˜¯æŒ‡åˆ†ç±»içš„True Negativeï¼›

FNiæ˜¯æŒ‡åˆ†ç±»içš„False Negativeã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬æ¥ç®—microç²¾åº¦(precision)

precisionmi=TP1+TP2+TP3TP1+FP1+TP2+FP2+TP3+FP3

ä»¥åŠmicroå¬å›(recall)

recallmi=TP1+TP2+TP3TP1+FN1+TP2+FN2+TP3+FN3

æœ€åmicro-F1çš„è®¡ç®—å…¬å¼ä¸º

F1,mi=2recallmiÃ—precisionmirecallmi+precisionmi



å¦‚æœè¿™ä¸ªæ•°æ®é›†ä¸­å„ä¸ªç±»çš„åˆ†å¸ƒä¸å¹³è¡¡çš„è¯ï¼Œæ›´å»ºè®®ä½¿ç”¨mirco-F1ï¼Œå› ä¸ºmacroæ²¡æœ‰è€ƒè™‘åˆ°å„ä¸ªç±»åˆ«çš„æ ·æœ¬å¤§å°ã€‚
------------------------------------------------------------------------------------------------------
ä»»åŠ¡ä¸€ï¼š æ•´ç†ç°åœ¨æœ‰å“ªäº›å¼€æºæ•°æ®é›†ï¼Œæ•°æ®é›†å¤§å°ã€æ ¼å¼ï¼›
2020/3/30
    å¦‚ä½•æŸ¥çœ‹datasetçš„æ ¼å¼ï¼šhttps://blog.csdn.net/hulumei123/article/details/90490027
        æ¨èä½¿ç”¨pycharmè¯»å–
            pycharmä¸­ä½¿ç”¨python consoleï¼Œ 
                import json
                source = json.load(json.path)
                
                ä½¿ç”¨pd.read_json()ä¸ä¼šåœ¨special variablesæ¡†ä¸­æ˜¾ç¤º
                ä½¿ç”¨pd.read_csv()è¯»å–jsonæ–‡ä»¶ä¼šå†…å­˜æº¢å‡ºæŠ¥é”™ï¼Œåˆ«é—®æˆ‘æ˜¯æ€ä¹ˆçŸ¥é“çš„ã€‚ã€‚

    csv å’Œ jsonçš„åŒºåˆ«ï¼š
        csvå’Œjsonæ˜¯Pythoné‡Œé¢å¸¸è§çš„æ–‡æœ¬æ•°æ®ä¿å­˜æ ¼å¼ï¼Œ

            1ã€csvæ–‡ä»¶å¯ä»¥ç”¨exelæ‰“å¼€ï¼Œé‡Œé¢çš„å†…å®¹æ ¼å¼ï¼šæ•°æ®ä¹‹é—´æ˜¯ä½¿ç”¨â€˜ï¼Œâ€™éš”å¼€ã€‚

            [,..........,]   ç”¨excelæ‰“å¼€ä¸€ä¸ªï¼Œå°±æ˜¯éš”ç€ä¸€åˆ—

            2ã€jsonæ•°æ®æ ¼å¼æ˜¯ï¼Œä¿å­˜ä¸€å¼ åˆ—è¡¨ï¼Œåˆ—è¡¨æˆå‘˜ä¸€èˆ¬æ˜¯å­—å…¸ï¼Œå­—å…¸å†å»ä¿å­˜æ•°å€¼

            [{},{}...........]

    tsvå’Œcsvçš„åŒºåˆ«
        TSVæ–‡ä»¶å’ŒCSVçš„æ–‡ä»¶çš„åŒºåˆ«æ˜¯ï¼šå‰è€…ä½¿ç”¨\tä½œä¸ºåˆ†éš”ç¬¦ï¼Œåè€…ä½¿ç”¨,ä½œä¸ºåˆ†éš”ç¬¦ã€‚
        ä½¿ç”¨pandasè¯»å–tsvæ–‡ä»¶çš„ä»£ç å¦‚ä¸‹ï¼š
            train=pd.read_csv('test.tsv', sep='\t')
    
    jsonlï¼š json linesæ–‡ä»¶ï¼Œ json linesæ–‡ä»¶æ˜¯ä¸€ç§ä¾¿äºå­˜å‚¨ç»“æ„åŒ–æ•°æ®çš„æ ¼å¼ï¼Œå¯ä»¥ä¸€æ¬¡å¤„ç†ä¸€æ¡è®°å½•ã€‚å¯ä»¥ç”¨ä½œæ—¥å¿—æ–‡ä»¶æˆ–è€…å…¶ä»–ã€‚æ¯æ¡jsonæ•°æ®ä¹‹é—´å­˜åœ¨ä¸€ä¸ª"\n"åˆ†éš”ç¬¦ã€‚
        è¯»å–jsonlï¼Œç”¨json.load(),pycharmå¯ä»¥æ ‘å½¢æ˜¾ç¤ºæ ¼å¼
            with open('./multinli_1.0/multinli_1.0/multinli_1.0_train.jsonl', 'r') as json_file:
                json_list = list(json_file)

            for json_str in json_list:
                result = json.loads(json_str)
                print("result: {}".format(result))
                print(isinstance(result, dict))

    train\dev(ä¹Ÿå«validation set)\testé›†

        trainé›†å¯ä»¥ä¸å’Œdevã€testé›†åŒåˆ†å¸ƒ
        devé›†ä¸€å®šè¦å’Œtesté›†åŒåˆ†å¸ƒ

        ä¸»è¦ç–‘é—®æ˜¯devé›†ä¸ºä»€ä¹ˆè¦ä»testé›†ä¸­åˆ†ç¦»å‡ºæ¥ï¼Ÿ
            devé›†çš„å­˜åœ¨å¾ˆå¥½ç†è§£ï¼Œè¦å¯¹ç”¨ä¸åŒåˆ†å¸ƒæ•°æ®è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹åšå‚æ•°ä¸Šçš„è°ƒæ•´ã€‚
            é‚£è¿˜è¦testé›†åšä»€ä¹ˆï¼Ÿ
                å› ä¸ºå¦‚æœåœ¨devé›†ä¸Šè¿‡æ‹Ÿåˆäº†æ€ä¹ˆåŠï¼Ÿé‚£å°±å¯èƒ½devé›†ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†æ˜¯å®é™…åº”ç”¨æ—¶å¯èƒ½å·®å¾—è¿œã€‚â€”â€”è¿™å°±æ˜¯testé›†çš„å­˜åœ¨æ„ä¹‰ï¼Œæ£€æµ‹devé›†ä¸Šæ˜¯å¦è¿‡æ‹Ÿåˆã€‚

    token å’Œ tokenization
        token(ç¬¦å·):åŒ…æ‹¬å•è¯å’Œæ ‡ç‚¹

        tokenization(åˆ†è¯,ä¹Ÿå«åšword segmentation)ï¼šæˆ‘æ˜¯ä¸­å›½äºº->['æˆ‘', 'æ˜¯', 'ä¸­å›½äºº']

    è‡ªç„¶è¯­è¨€å¤„ç†é‡Œçš„ IOB tagging æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
        BIO/IOB tagging æ˜¯ä¸€ç§å¯¹ç»™å®šå¥å­ä¸­çš„å•å…ƒåšåºåˆ—æ ‡æ³¨çš„æ–¹å¼ï¼Œç”¨äºä»ç»™å®šå¥å­ä¸­æŠ½å–è¿ç»­å­—/è¯å—æ„æˆçš„æœ‰æ„ä¹‰çŸ­è¯­ï¼Œä¾‹å¦‚åè¯çŸ­è¯­ï¼ˆnoun phrases, NPï¼‰ã€å‘½åå®ä½“ï¼ˆnamed entites, NEï¼‰ç­‰ã€‚å¯¹äºä¸€ä¸ªç»™å®šå¥å­ï¼Œå°†å…¶ä¸­æ¯ä¸ªè¯æ ‡æ³¨ä¸ºBï¼ˆBeginningï¼ŒæŒ‡ç¤ºæŸçŸ­è¯­èµ·å§‹ï¼‰ã€Iï¼ˆInsideï¼ŒæŒ‡ç¤ºçŸ­è¯­å†…éƒ¨ï¼‰ã€Oï¼ˆOutsideï¼ŒæŒ‡ç¤ºä¸åœ¨çŸ­è¯­ä¸­ï¼‰ä¸­çš„ä¸€ä¸ªã€‚ä»¥å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä¸ºä¾‹å¯ä»¥å°†John supports Leceister Cityè¿™å¥è¯é‡Œçš„å››ä¸ªè¯åˆ†åˆ«æ ‡æ³¨ä¸ºï¼šB-äººå O B-æœºæ„å I-æœºæ„åã€‚ ç±»ä¼¼å˜ä½“è¿˜æœ‰BILOUç­‰â€¦â€¦


    constituent parsing & dependency parsing
        å¥æ³•åˆ†ææ˜¯å¯¹å¥å­è¿›è¡Œåˆ†æéå¸¸é‡è¦çš„éƒ¨åˆ†ï¼Œä¸»è¦åŒ…æ‹¬constituency parsing(æˆåˆ†å¥æ³•åˆ†æ)å’Œdependency parsing(ä¾å­˜å¥æ³•åˆ†æ)ï¼Œä¸¤è€…å…·æœ‰éå¸¸å¤§çš„å·®å¼‚ã€‚
        
        æˆåˆ†åˆ†æï¼ˆconstituent parsingï¼‰
            æˆåˆ†åˆ†ææ ‘æ˜¯å°†ä¸€ä¸ªæ–‡æœ¬åˆ†æˆçŸ­è¯­ï¼Œæ ‘ä¸­çš„éå¶å­èŠ‚ç‚¹æ˜¯çŸ­è¯­çš„ç±»å‹ã€‚
            å¦‚ï¼š
                            Sentence
                                    |
                    +-------------+------------+
                    |                          |
                Noun Phrase                Verb Phrase
                    |                          |
                    John                 +-------+--------+
                                        |                |
                                        Verb          Noun Phrase
                                        |                |
                                        sees              Bill

            æœ‰ä¸“é—¨çš„å¥æ³•æ ‘çš„æ„æˆè§„åˆ™ï¼Œè¯¦è§ï¼šhttps://www.ling.upenn.edu/~beatrice/annotation/syn-intro.htm#ordinary_ips
            ä¾‹ï¼š 
                (ROOT (IP (PP (P åœ¨) (NP (DNP (NP (NN ç§‹å¤©)) (DEC çš„)) (NP (NN æ—¶å€™)))) (PU ï¼Œ) (NP (NR é™¶å–†)) (VP (VV çˆ±) (IP (VP (VV åƒ) (NP (NN è‹¹æœ)))))))
                å›¾è§ï¼šhttps://app.yinxiang.com/Home.action#n=189f1a0a-8a40-4860-9a52-fe5d35ad050d&s=s47&ses=4&sh=5&sds=2&
        
        ä¾èµ–åˆ†æï¼ˆdependency parsingï¼‰
            ä¾å­˜å¥æ³•æ ‘èƒ½å¤Ÿæ ¹æ®æˆåˆ†å¥æ³•æ ‘è½¬æ¢è€Œæ¥ï¼Œä½†æˆåˆ†å¥æ³•æ ‘ä¸èƒ½é€šè¿‡ä¾å­˜æ ‘è½¬åŒ–æ¥ã€‚
                root(ROOT-0, çˆ±-7)
                case(æ—¶å€™-4, åœ¨-1)
                nmod:assmod(æ—¶å€™-4, ç§‹å¤©-2)
                dep(ç§‹å¤©-2, çš„-3)
                nmod:prep(çˆ±-7, æ—¶å€™-4)
                punct(çˆ±-7, ï¼Œ-5)
                nsubj(çˆ±-7, é™¶å–†-6)
                ccomp(çˆ±-7, åƒ-8)
                dobj(åƒ-8, è‹¹æœ-9)
                å›¾ï¼šhttps://app.yinxiang.com/Home.action#n=189f1a0a-8a40-4860-9a52-fe5d35ad050d&s=s47&ses=4&sh=5&sds=2&x=jsonl&
        
        Head word
            ä¸€ä¸ªé•¿çŸ­è¯­çš„head wordè¡¨ç¤ºæœ€èƒ½è¡¨ç¤ºæ•´ä¸ªçŸ­è¯­çš„é‚£ä¸ªè¯ï¼Œåè¯çŸ­è¯­ä¸€èˆ¬æ˜¯åè¯ï¼ŒåŠ¨è¯çŸ­è¯­ä¸€èˆ¬æ˜¯åŠ¨è¯ã€‚
                åœ¨â€å¸ƒæœ—è®¿é—®ä¸Šæµ·â€œè¿™ä¸€æ•´æ£µæ ‘ä¸­head wordå°±æ˜¯â€œè®¿é—®â€è¿™ä¸ªè¯ï¼Œè€Œåœ¨å³å­æ ‘ä¸Šhead wordæ˜¯â€œè®¿é—®â€ã€‚
                å›¾è§ï¼šhttps://app.yinxiang.com/Home.action#n=189f1a0a-8a40-4860-9a52-fe5d35ad050d&s=s47&ses=4&sh=5&sds=2&




-------------------------------------------------------------------------------------------------------------------------------------------------
HMMï¼ˆéšé©¬å°”ç§‘å¤«æ¨¡å‹ï¼‰   ------->   CRF(æ¡ä»¶éšå³åœº)

HMM
    éšå³è¿‡ç¨‹å’Œéšæœºå˜é‡
        éšæœºè¿‡ç¨‹ï¼Œå¦‚è‚¡ç¥¨çš„èµ°åŠ¿ï¼Œè‚¡ç¥¨ä»·æ ¼æœ¬èº«æ˜¯ä¸ªæœªçŸ¥çš„ï¼Œä½†æ˜¯t+1æ—¶åˆ»çš„ä»·æ ¼å’Œtæ—¶åˆ»çš„ä»·æ ¼æœ‰å…³ç³»ï¼Œè¿™æ°æ°æ˜¯äººä»¬æ„Ÿå…´è¶£çš„ã€‚æ•´ä¸ªè¿‡ç¨‹æ˜¯éšæœºçš„ï¼Œä½†è¿‡ç¨‹ä¹‹ä¸­çš„ç›¸é‚»ç‚¹å´æ˜¯ç›¸å…³çš„ã€‚  å½“ç„¶ï¼Œéšæœºè¿‡ç¨‹çš„çŠ¶æ€åº¦é‡ä¸ä¸€å®šæ˜¯æ—¶é—´tï¼Œè¿˜å¯ä»¥æ˜¯å„ç§â€œpathâ€ã€‚
        ä»¥å¾€éšæœºå˜é‡ä¹‹é—´éƒ½æ˜¯ä¸ç›¸å…³çš„ï¼Œè¿™ä½“ç°äº†è¿›æ­¥ã€‚
        å‚è€ƒï¼šhttps://www.zhihu.com/question/280948058

    ç‹¬ç«‹æ€§è¾“å‡ºå‡è®¾ï¼š
        
        P(o1,o2,o3,...|s1,s2,s3....)=P(o1|s1)*P(o2|s2)*P(o3|s3)...  ä»æ„ä¹‰ä¸Šç†è§£å®ƒçš„å®šä¹‰äº†ï¼Œå…¬å¼ä¸Šä¸å¥½æ¨


CRF 
    A CRF can be considered as a generalization of HMM or we can say that a HMM is a particular case of CRF where constant probabilities are used to model state transitions.
    åˆ¤åˆ«å¼æ¨¡å‹
        åˆ¤åˆ«å¼æ¨¡å‹ discriminative model è®¡ç®—æ¡ä»¶æ¦‚ç‡ï¼Œ
            ç»™å‡ºxé¢„æµ‹y
        è€Œç”Ÿæˆå¼æ¨¡å‹ generative model è®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚
            ç»™å‡ºPï¼ˆxï¼Œyï¼‰å’Œxï¼Œæ±‚ä½¿Pï¼ˆxï¼Œ yï¼‰æœ€å¤§çš„y
    It has been observed that CRF-based learning method was more suitable for mining aspects, opinions and intensifiers (including phrases) in comparison to LHMMs based and statistical methods. 


    The task of assigning labels to a set of observation sequences arises in many fields, 

    åœ¨å¾ˆå¤šåº”ç”¨é‡Œï¼Œæˆ‘ä»¬éƒ½å¸Œæœ›èƒ½å¤Ÿé¢„æµ‹ç›¸äº’å…³è”çš„å¤šä¸ªå˜é‡ã€‚å¦‚ä¸€ä¸ªsports teamçš„æ¯”èµ›è¡¨ç°å’Œæ¯ä½é˜Ÿå‘˜çš„å¥åº·çŠ¶å†µæœ‰å…³ï¼Œè€Œé˜Ÿå‘˜çš„å¥åº·çŠ¶å†µå’Œteamçš„æ¯”èµ›å¯†åº¦å®‰æ’å’Œè¡Œç¨‹åŠ³é¡¿ç¨‹åº¦æœ‰å…³ã€‚æ¯”èµ›ç»“æœè¿˜å’Œå£«æ°”æœ‰å…³ï¼Œè€Œå£«æ°”åˆåè¿‡æ¥å½±å“å¥åº·çŠ¶å†µã€‚

    å¯ä»¥çœ‹å‡ºï¼Œå¤šä¸ªå˜é‡å½¼æ­¤å†…éƒ¨ç›¸å…³è”ã€‚ç”¨CRFæ¡ä»¶éšæœºåœºæ¥è§£å†³æ­¤ç±»é—®é¢˜éå¸¸æœ‰æ•ˆã€‚
    æœ‰è®¸å¤šç±»ä¼¼åº”ç”¨ï¼Œ å¦‚æŠ½å–NLPå¥æ³•ï¼Œå›¾ç‰‡åŒºåŸŸçš„åˆ’åˆ†ï¼ŒDNAé“¾çš„åˆ’åˆ†ã€‚

    åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ ¹æ®è§‚æµ‹åˆ°çš„ç‰¹å¾çŸ¢é‡ï¼Œæ¥é¢„æµ‹ä¸€äº›éšæœºå˜é‡ã€‚

    1. graphical model
        graphical modelæ˜¯è¡¨ç¤ºè¿™ç§ç›¸äº’ä¹‹é—´å…³ç³»çš„ä¸€ä¸ªè‡ªç„¶çš„åšæ³•ã€‚graphical model åŒ…æ‹¬Bayesian ç½‘ç»œï¼Œç¥ç»ç½‘ç»œï¼Œfactor graphsï¼Œé©¬å°”ç§‘å¤«éšæœºåœºç­‰ç­‰ã€‚ 
    
    2. ä¸ºä»€ä¹ˆåªæœ‰æœ‰graphical modelä¸å¤Ÿï¼Ÿ  -----è¦åˆ ç¹å°±ç®€
        å¤§å¤šæ•°NLPçš„åº”ç”¨éƒ½æœŸæœ›å¾—åˆ°è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå°±æ˜¯å¾—åˆ°ç”Ÿæˆæ¨¡å‹ã€‚
        A generative model is a model for randomly generating observable data based on given parameters. 
        ç”Ÿæˆæ¨¡å‹è™½ç„¶æœ‰ç§ç§å¥½å¤„ï¼Œä½†æ˜¯ä¹Ÿæœ‰ä¸å°‘å¼Šç«¯ï¼Œå¦‚è¾“å…¥æ•°æ®çš„ç»´åº¦ä¸€èˆ¬å¾ˆå¤§ï¼Œå¹¶ä¸”ç‰¹å¾ä¹‹é—´æœ‰å¾ˆå¤æ‚çš„ä¾èµ–å…³ç³»ï¼Œæ‰€ä»¥æ ¹æ®è¿™ä¸¤è€…æ„å»ºä¸€ä¸ªæ¦‚ç‡æ¨¡å‹å¾ˆéš¾ï¼Œå³ä¾¿çœŸçš„æ„å»ºå‡ºæ¥ä¹Ÿä¼šå¾ˆå¤æ‚ï¼Œå¾ˆå¯èƒ½è¿‡æ‹Ÿåˆã€‚

        æ‰€ä»¥ä¸å¦‚æˆ‘ä»¬éƒ¨åˆ†å¿½ç•¥è¿™äº›ä¾èµ–ï¼ŒCRFåªè€ƒè™‘è¾“å…¥ä¸´è¿‘çš„æ•°æ®ï¼Ÿ
            å¦‚ç”¨ç±³é¥­åœ¨ç›˜å­ä¸ŠçŒœä¸€ä¸ªèœè‚´ï¼Œæˆ‘ä»¬å¾ˆéš¾çŒœï¼Œå› ä¸ºè¿™æ ·çš„ä¾‹å­å¤ªå¤šäº†ã€‚å¦‚æœå‘Šè¯‰ä½ ä»–æ—è¾¹æœ‰æ‰¬å·é¢æ¡ï¼Œæ‰¬å·çƒ¤é¸­ï¼Œæ‰¬å·é‡Œè„Šï¼Œä½ å¯èƒ½å°±èƒ½çŒœå‡ºè¿™æ˜¯æ‰¬å·ç‚’é¥­äº†ã€‚è¿™å°±æ˜¯CRFçš„åŸç†ã€‚è‡³äºæ¡Œå­å› è¿™ä¸ªèœä¸‹æ²‰äº†å‡ å¾®ç±³ï¼Œç©ºæ°”æµåŠ¨å› ä¸ºè¿™ä¸ªèœæ”¶åˆ°äº†ä»€ä¹ˆå½±å“å°±ä¸å»ç®¡äº†ã€‚

            HMMå°±æ˜¯å¿½ç•¥çš„å¤ªå¤šäº†ï¼Œåªåˆ©ç”¨äº†ç±³é¥­å’Œç›˜å­è¿™ä¸€ä¸ªç›¸å…³ä¿¡æ¯ï¼Œæ²¡æœ‰åˆ©ç”¨ä¸´è¿‘ä¿¡æ¯ã€‚
---------------------------------------------------------------------------
    CRFå¦‚ä½•è§£å†³graphical modelsé¢ä¸´çš„é—®é¢˜ï¼Ÿ  ï¼ˆCRFä¹Ÿæ˜¯ä¸€ç§graphical modelï¼‰
        ä¸€ç§è§£å†³æ–¹æ³•æ˜¯ç›´æ¥å°†æ¡ä»¶åˆ†å¸ƒmodelå‡ºæ¥ï¼Œå¯¹äºåˆ†ç±»é—®é¢˜æ¥è¯´è¿™å°±æ˜¯æ‰€éœ€çš„å…¨éƒ¨äº†ã€‚/ï¼Ÿ/
        CRFæœ¬è´¨ä¸Šæ˜¯å°†classificationå’Œgraphical modelingçš„ä¼˜åŠ¿ç»“åˆåœ¨ä¸€èµ·ã€‚å°†åˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œé¢„æµ‹å’Œåˆ©ç”¨compactly å¤šå˜é‡æ•°æ®å»ºæ¨¡çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ã€‚
        
        /ï¼Ÿ/ä»æŸç§è§’åº¦æ¥è¯´ï¼Œç”Ÿæˆæ¨¡å‹å’ŒCRFçš„å…³ç³»å¯ä»¥ç±»æ¯”äºæœ´ç´ è´å¶æ–¯å’Œé€»è¾‘å›å½’åˆ†ç±»ã€‚
        /ï¼Ÿ/å…¶å®å¤šé¡¹å¼é€»è¾‘å›å½’æ¨¡å‹å¯ä»¥è¢«çœ‹ä½œæœ€ç®€å•çš„ä¸€ç§CRF--åªæœ‰ä¸€ä¸ªè¾“å‡ºå˜é‡ã€‚
        /*/ å¡«å‘ï¼šæœ´ç´ è´å¶æ–¯   é€»è¾‘å›å½’

    
    æ‰€ä»¥ç©¶ç«Ÿä»€ä¹ˆæ˜¯CRFï¼Ÿ
        ç”¨æ¥åˆ†ç±»å’Œsegmenting ç»“æ„æ•°æ®ï¼Œå¦‚åºåˆ—ï¼Œæ ‘å’Œlatticeã€‚CRFå°¤å…¶é€‚åˆäºå¯¹æ—¶åºæ•°æ®è¿›è¡Œå»ºæ¨¡ï¼ˆå› ä¸ºæ—¶é—´ä¾èµ–å¯ä»¥é€šè¿‡å„ç§ä¸åŒçš„æ–¹å¼è¡¨è¾¾ï¼‰ï¼ŒThe underlying idea is that of defining a conditional probability distribution over label sequences given a particular observation sequence, rather than a joint distribution over both label and observation sequences. 

        CRFçš„ä¸»è¦ä¼˜åŠ¿æ˜¯æ”¾å®½ç‹¬ç«‹å‡è®¾ï¼ˆthe variables donâ€™t depend on each other and they donâ€™t affect each other in any wayï¼‰å–å¾—çš„ã€‚
    
    HMM vs CRF  /?/
        HMM is a generative model and it gives the output directly by modeling the transition matrix based on the training data. The results can be improved by providing more datapoints, but there is no direct control over the output labels. HMM learns the transition probabilities on its own based on the training data provided. Hence if we provide more datapoints, then we can improve the model to include wider variety. CRF is a discriminative model which outputs a confidence measure. This is really useful in most cases because we want to know how sure the model is about the label at that point. This confidence measure can be thresholded to suit various applications. The good thing about confidence measure is that the number of false alarms is low compared to HMM.

        The primary advantage of CRFs over HMMs is their conditional nature, resulting in the relaxation of the independence assumptions required by HMMs. Additionally, CRFs avoid the label bias problem, a weakness exhibited by Markov models based on directed graphical models.
        /*/ A CRF can be considered as a generalization of HMM or we can say that a HMM is a particular case of CRF where constant probabilities are used to model state transitions. CRFs outperform HMMs on a number of real-world sequence labeling tasks.

        /ï¼Ÿ/å¡«å‘ï¼šHMMçš„ï¼šlabe   l bias problemï¼ˆæœ‰å‘å›¾çš„å¤©ç”Ÿä¸è¶³ï¼Œæ— å‘å›¾å¦‚CRFæ— æ­¤ç¼ºç‚¹ï¼‰

        There are many libraries available out there like HCRF, CRFall, CRF++ etc, that have CRF functionalities nicely defined and implemented. You can check them out and see how they work out for your project.

    

---------------------------------------------------------------------------
https://towardsdatascience.com/implementing-a-linear-chain-conditional-random-field-crf-in-pytorch-16b0b9c4b4ea

code implement for CRF  
    Over the last few years, CRFs models were combined with LSTMs to get state-of-the-art results. In the NLP community this was considered a rule of thumb for sequence tagging: if you want more accuracy just stack a CRF on top of your LSTM layer and bang â­ï¸! You can see some examples here or here.

    In a sequence classification problem, our final objective is to find the probability of a sequence of labels (y) given an input of sequence vectors (X). This is denoted as P(y | X).

    å›¾1ï¼šhttps://app.yinxiang.com/Home.action#n=b36da91d-e2b6-44ae-9a65-ca2d96928dcb&s=s47&ses=4&sh=5&sds=2&x=crf&
    These are some intuitions of why we use exp:
        Underflow: When we multiply very small numbers, we get a smaller number which may suffer underflow.
        Non-negative outputs: All values are mapped between 0 and +inf.
        Monotonically increasing: It pushes high values up and low values down. This has a similar effect with an argmax operation. More here.

    Now we are going to add new learnable weights to model the chance of a label yk being followed by yk+1. By modelling this, we are creating a dependency between successive labels! Thus, the name linear-chain CRF! In order to do so, we multiply our previous probability by P(yk+1 | yk), for which we can use exponential properties to rewrite it as unary scores U(x, y) plus learnable transition scores T(y, y):
    å›¾2ï¼šhttps://app.yinxiang.com/Home.action#n=b36da91d-e2b6-44ae-9a65-ca2d96928dcb&s=s47&ses=4&sh=5&sds=2&x=crf&


    å›¾3ï¼šhttps://app.yinxiang.com/Home.action#n=b36da91d-e2b6-44ae-9a65-ca2d96928dcb&s=s47&ses=4&sh=5&sds=2&x=crf&
    Turns out itâ€™s not trivial to compute Z(X) because we have too many nested loops ğŸ˜–! Itâ€™s a sum over all possible combinations over the label set at each timestep. To be more precise, we have â„“ computations over the label set. This give us a time complexity of O(|y|^â„“).
    
    Luckily, we can exploit the recurrent dependencies and use dynamic programmingï¼ˆåŠ¨æ€è§„åˆ’ï¼‰ to compute it efficiently ğŸ˜! The algorithm that does this is called forward algorithm or backward algorithm â€” depending on the order that you iterate over the sequence.
--------------------------------------------------------------------------------------------------------------------------

æ˜¾ç¤ºç‰¹å¾explicitï¼šâ€œI love the touchscreen of my phone but the battery life is so shortã€‚

éšå¼ç‰¹å¾implicitï¼š â€œThis camera is sleek and very affordableâ€œ


-----------------------------------------------------------------------------------------------------------------------




