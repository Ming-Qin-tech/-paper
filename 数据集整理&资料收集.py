
ä»»åŠ¡ä¸€ï¼š æ•´ç†ç°åœ¨æœ‰å“ªäº›å¼€æºæ•°æ®é›†ï¼Œæ•°æ®é›†å¤§å°ã€æ ¼å¼ï¼›
2020/3/30
    å¦‚ä½•æŸ¥çœ‹datasetçš„æ ¼å¼ï¼šhttps://blog.csdn.net/hulumei123/article/details/90490027
        æ¨èä½¿ç”¨pycharmè¯»å–
            pycharmä¸­ä½¿ç”¨python consoleï¼Œ 
                import json
                source = json.load(json.path)
                
                ä½¿ç”¨pd.read_json()ä¸ä¼šåœ¨special variablesæ¡†ä¸­æ˜¾ç¤º
                ä½¿ç”¨pd.read_csv()è¯»å–jsonæ–‡ä»¶ä¼šå†…å­˜æº¢å‡ºæŠ¥é”™ï¼Œåˆ«é—®æˆ‘æ˜¯æ€ä¹ˆçŸ¥é“çš„ã€‚ã€‚

    csv å’Œ jsonçš„åŒºåˆ«ï¼š
        csvå’Œjsonæ˜¯Pythoné‡Œé¢å¸¸è§çš„æ–‡æœ¬æ•°æ®ä¿å­˜æ ¼å¼ï¼Œ

            1ã€csvæ–‡ä»¶å¯ä»¥ç”¨exelæ‰“å¼€ï¼Œé‡Œé¢çš„å†…å®¹æ ¼å¼ï¼šæ•°æ®ä¹‹é—´æ˜¯ä½¿ç”¨â€˜ï¼Œâ€™éš”å¼€ã€‚

            [,..........,]   ç”¨excelæ‰“å¼€ä¸€ä¸ªï¼Œå°±æ˜¯éš”ç€ä¸€åˆ—

            2ã€jsonæ•°æ®æ ¼å¼æ˜¯ï¼Œä¿å­˜ä¸€å¼ åˆ—è¡¨ï¼Œåˆ—è¡¨æˆå‘˜ä¸€èˆ¬æ˜¯å­—å…¸ï¼Œå­—å…¸å†å»ä¿å­˜æ•°å€¼

            [{},{}...........]

    tsvå’Œcsvçš„åŒºåˆ«
        TSVæ–‡ä»¶å’ŒCSVçš„æ–‡ä»¶çš„åŒºåˆ«æ˜¯ï¼šå‰è€…ä½¿ç”¨\tä½œä¸ºåˆ†éš”ç¬¦ï¼Œåè€…ä½¿ç”¨,ä½œä¸ºåˆ†éš”ç¬¦ã€‚
        ä½¿ç”¨pandasè¯»å–tsvæ–‡ä»¶çš„ä»£ç å¦‚ä¸‹ï¼š
            train=pd.read_csv('test.tsv', sep='\t')
    
    jsonlï¼š json linesæ–‡ä»¶ï¼Œ json linesæ–‡ä»¶æ˜¯ä¸€ç§ä¾¿äºå­˜å‚¨ç»“æ„åŒ–æ•°æ®çš„æ ¼å¼ï¼Œå¯ä»¥ä¸€æ¬¡å¤„ç†ä¸€æ¡è®°å½•ã€‚å¯ä»¥ç”¨ä½œæ—¥å¿—æ–‡ä»¶æˆ–è€…å…¶ä»–ã€‚æ¯æ¡jsonæ•°æ®ä¹‹é—´å­˜åœ¨ä¸€ä¸ª"\n"åˆ†éš”ç¬¦ã€‚
        è¯»å–jsonlï¼Œç”¨json.load(),pycharmå¯ä»¥æ ‘å½¢æ˜¾ç¤ºæ ¼å¼
            with open('./multinli_1.0/multinli_1.0/multinli_1.0_train.jsonl', 'r') as json_file:
                json_list = list(json_file)

            for json_str in json_list:
                result = json.loads(json_str)
                print("result: {}".format(result))
                print(isinstance(result, dict))

    train\dev(ä¹Ÿå«validation set)\testé›†

        trainé›†å¯ä»¥ä¸å’Œdevã€testé›†åŒåˆ†å¸ƒ
        devé›†ä¸€å®šè¦å’Œtesté›†åŒåˆ†å¸ƒ

        ä¸»è¦ç–‘é—®æ˜¯devé›†ä¸ºä»€ä¹ˆè¦ä»testé›†ä¸­åˆ†ç¦»å‡ºæ¥ï¼Ÿ
            devé›†çš„å­˜åœ¨å¾ˆå¥½ç†è§£ï¼Œè¦å¯¹ç”¨ä¸åŒåˆ†å¸ƒæ•°æ®è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹åšå‚æ•°ä¸Šçš„è°ƒæ•´ã€‚
            é‚£è¿˜è¦testé›†åšä»€ä¹ˆï¼Ÿ
                å› ä¸ºå¦‚æœåœ¨devé›†ä¸Šè¿‡æ‹Ÿåˆäº†æ€ä¹ˆåŠï¼Ÿé‚£å°±å¯èƒ½devé›†ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†æ˜¯å®é™…åº”ç”¨æ—¶å¯èƒ½å·®å¾—è¿œã€‚â€”â€”è¿™å°±æ˜¯testé›†çš„å­˜åœ¨æ„ä¹‰ï¼Œæ£€æµ‹devé›†ä¸Šæ˜¯å¦è¿‡æ‹Ÿåˆã€‚

    token å’Œ tokenization
        token(ç¬¦å·):åŒ…æ‹¬å•è¯å’Œæ ‡ç‚¹

        tokenization(åˆ†è¯,ä¹Ÿå«åšword segmentation)ï¼šæˆ‘æ˜¯ä¸­å›½äºº->['æˆ‘', 'æ˜¯', 'ä¸­å›½äºº']

    è‡ªç„¶è¯­è¨€å¤„ç†é‡Œçš„ IOB tagging æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ
        BIO/IOB tagging æ˜¯ä¸€ç§å¯¹ç»™å®šå¥å­ä¸­çš„å•å…ƒåšåºåˆ—æ ‡æ³¨çš„æ–¹å¼ï¼Œç”¨äºä»ç»™å®šå¥å­ä¸­æŠ½å–è¿ç»­å­—/è¯å—æ„æˆçš„æœ‰æ„ä¹‰çŸ­è¯­ï¼Œä¾‹å¦‚åè¯çŸ­è¯­ï¼ˆnoun phrases, NPï¼‰ã€å‘½åå®ä½“ï¼ˆnamed entites, NEï¼‰ç­‰ã€‚å¯¹äºä¸€ä¸ªç»™å®šå¥å­ï¼Œå°†å…¶ä¸­æ¯ä¸ªè¯æ ‡æ³¨ä¸ºBï¼ˆBeginningï¼ŒæŒ‡ç¤ºæŸçŸ­è¯­èµ·å§‹ï¼‰ã€Iï¼ˆInsideï¼ŒæŒ‡ç¤ºçŸ­è¯­å†…éƒ¨ï¼‰ã€Oï¼ˆOutsideï¼ŒæŒ‡ç¤ºä¸åœ¨çŸ­è¯­ä¸­ï¼‰ä¸­çš„ä¸€ä¸ªã€‚ä»¥å‘½åå®ä½“è¯†åˆ«ï¼ˆNERï¼‰ä¸ºä¾‹å¯ä»¥å°†John supports Leceister Cityè¿™å¥è¯é‡Œçš„å››ä¸ªè¯åˆ†åˆ«æ ‡æ³¨ä¸ºï¼šB-äººå O B-æœºæ„å I-æœºæ„åã€‚ ç±»ä¼¼å˜ä½“è¿˜æœ‰BILOUç­‰â€¦â€¦


    constituent parsing & dependency parsing
        å¥æ³•åˆ†ææ˜¯å¯¹å¥å­è¿›è¡Œåˆ†æéå¸¸é‡è¦çš„éƒ¨åˆ†ï¼Œä¸»è¦åŒ…æ‹¬constituency parsing(æˆåˆ†å¥æ³•åˆ†æ)å’Œdependency parsing(ä¾å­˜å¥æ³•åˆ†æ)ï¼Œä¸¤è€…å…·æœ‰éå¸¸å¤§çš„å·®å¼‚ã€‚
        
        æˆåˆ†åˆ†æï¼ˆconstituent parsingï¼‰
            æˆåˆ†åˆ†ææ ‘æ˜¯å°†ä¸€ä¸ªæ–‡æœ¬åˆ†æˆçŸ­è¯­ï¼Œæ ‘ä¸­çš„éå¶å­èŠ‚ç‚¹æ˜¯çŸ­è¯­çš„ç±»å‹ã€‚
            å¦‚ï¼š
                            Sentence
                                    |
                    +-------------+------------+
                    |                          |
                Noun Phrase                Verb Phrase
                    |                          |
                    John                 +-------+--------+
                                        |                |
                                        Verb          Noun Phrase
                                        |                |
                                        sees              Bill

            æœ‰ä¸“é—¨çš„å¥æ³•æ ‘çš„æ„æˆè§„åˆ™ï¼Œè¯¦è§ï¼šhttps://www.ling.upenn.edu/~beatrice/annotation/syn-intro.htm#ordinary_ips
            ä¾‹ï¼š 
                (ROOT (IP (PP (P åœ¨) (NP (DNP (NP (NN ç§‹å¤©)) (DEC çš„)) (NP (NN æ—¶å€™)))) (PU ï¼Œ) (NP (NR é™¶å–†)) (VP (VV çˆ±) (IP (VP (VV åƒ) (NP (NN è‹¹æœ)))))))
                å›¾è§ï¼šhttps://app.yinxiang.com/Home.action#n=189f1a0a-8a40-4860-9a52-fe5d35ad050d&s=s47&ses=4&sh=5&sds=2&
        
        ä¾èµ–åˆ†æï¼ˆdependency parsingï¼‰
            ä¾å­˜å¥æ³•æ ‘èƒ½å¤Ÿæ ¹æ®æˆåˆ†å¥æ³•æ ‘è½¬æ¢è€Œæ¥ï¼Œä½†æˆåˆ†å¥æ³•æ ‘ä¸èƒ½é€šè¿‡ä¾å­˜æ ‘è½¬åŒ–æ¥ã€‚
                root(ROOT-0, çˆ±-7)
                case(æ—¶å€™-4, åœ¨-1)
                nmod:assmod(æ—¶å€™-4, ç§‹å¤©-2)
                dep(ç§‹å¤©-2, çš„-3)
                nmod:prep(çˆ±-7, æ—¶å€™-4)
                punct(çˆ±-7, ï¼Œ-5)
                nsubj(çˆ±-7, é™¶å–†-6)
                ccomp(çˆ±-7, åƒ-8)
                dobj(åƒ-8, è‹¹æœ-9)
                å›¾ï¼šhttps://app.yinxiang.com/Home.action#n=189f1a0a-8a40-4860-9a52-fe5d35ad050d&s=s47&ses=4&sh=5&sds=2&x=jsonl&
        
        Head word
            ä¸€ä¸ªé•¿çŸ­è¯­çš„head wordè¡¨ç¤ºæœ€èƒ½è¡¨ç¤ºæ•´ä¸ªçŸ­è¯­çš„é‚£ä¸ªè¯ï¼Œåè¯çŸ­è¯­ä¸€èˆ¬æ˜¯åè¯ï¼ŒåŠ¨è¯çŸ­è¯­ä¸€èˆ¬æ˜¯åŠ¨è¯ã€‚
                åœ¨â€å¸ƒæœ—è®¿é—®ä¸Šæµ·â€œè¿™ä¸€æ•´æ£µæ ‘ä¸­head wordå°±æ˜¯â€œè®¿é—®â€è¿™ä¸ªè¯ï¼Œè€Œåœ¨å³å­æ ‘ä¸Šhead wordæ˜¯â€œè®¿é—®â€ã€‚
                å›¾è§ï¼šhttps://app.yinxiang.com/Home.action#n=189f1a0a-8a40-4860-9a52-fe5d35ad050d&s=s47&ses=4&sh=5&sds=2&





-----------------------------------------------------------------------------------------------------------------------------------------------------------------
    GLUE å¤§ç³»åˆ—ï¼ˆThe General Language Understanding Evaluation (GLUE) ,tensorflowä¸­æœ‰é›†æˆï¼‰ï¼š
        æœ‰å¥å­å’Œå¥å­å¯¹çš„æ•°æ®é›†å’Œä»»åŠ¡
        æœ‰ç°åœ¨çš„ç®—æ³•èƒ½è¾¾åˆ°çš„æœ€å¥½æ°´å¹³çš„æ˜¾ç¤º

        GLUE/cola(The Corpus of Linguistic Acceptability)
            æ ‡è®°çš„æ˜¯å¦æœ‰è¯­æ³•é”™è¯¯
            Corpus Sample
                c-05	0	*	Books were sent to each other by the students.
                swb04	1		She voted for herself.
            ç¬¬ä¸€åˆ—ï¼šencode representation
            ç¬¬äºŒåˆ—ï¼š äººå·¥æ ‡æ³¨é”™è¯¯
            ç¬¬ä¸‰åˆ—ï¼š åŸä½œè€…æ ‡æ³¨é”™è¯¯
            ç¬¬å››åˆ—ï¼š è¿™å¥è¯

        GLUE/sst2(The Stanford Sentiment Treebank )7.09 MiB  ç”±å‡ ä¸ªTXTæ–‡ä»¶ç»„æˆ
        train: 67,349   test:1821     validation:872 
            ç”µå½±è¯„è®ºï¼Œå¥å­çº§çš„æƒ…æ„Ÿææ€§ï¼Œåˆ©ç”¨äº†PTBæ•°æ®é›†ï¼Œ
                å¦‚
                    phrase ids|sentiment values
                        0|0.5
                        1|0.5
                        2|0.44444
                        3|0.5
                        4|0.42708
            Penn treebankï¼ˆPTBæ•°æ®é›†ï¼‰è¯æ€§æ ‡æ³¨é›†
                ä¸ºæ¯ä¸ªå•è¯æ ‡ä¸Šè¯æ€§
                    è¿‡å»æ¯å¥è¯çš„æˆåˆ†éƒ½æ˜¯ç”±ä¸“å®¶æ ‡æ³¨ï¼Œç„¶åå½¢æˆproduction ruleï¼ˆè§ä¸‹æ–‡è§£é‡Šï¼‰,é€Ÿåº¦æ…¢æˆæœ¬é«˜
                    ç°åœ¨æœ‰äº†äººä»¬ç²¾å¿ƒå»ºç«‹çš„treebankï¼Œè®¡ç®—æœºå°±å¯ä»¥é€šè¿‡ç®—æ³•ç›´æ¥ä»treebankä¸­æŠ½å–å‡ºproduction rule.

                treebankçš„é—®é¢˜ï¼š
                    æœ€å¤§çš„ä¸€ä¸ªé—®é¢˜æ˜¯ too big to failã€‚å› ä¸ºå»ºç«‹è¿™äº› treebank å¾ˆè´¹æ—¶è´¹åŠ›è´¹é’±ï¼Œæ‰€ä»¥å®ƒä»¬ä¸èƒ½è½»æ˜“çš„è¢«æ›¿ä»£ï¼›å¦å¤–ï¼Œå°½ç®¡å¤§å¤šæ•°çš„å†³å®šæ˜¯ç”±ä¸“å®¶æ¥åšçš„ï¼Œç„¶è€Œå¤§å¤šæ•°çš„ coding ç¡®æ˜¯ç”±éä¸“å®¶æ¥å®Œæˆçš„ï¼Œè€Œè¿™äº›äººä¹Ÿå¤„äºé«˜å‹ä»¥åŠæœ‰é™é¢„ç®—ä¸‹ï¼Œtreebank å¹¶ä¸æ˜¯å°½å–„å°½ç¾çš„ã€‚

                    äº§ç”Ÿå¼å’Œè•´å«å¼ï¼š
                        äº§ç”Ÿå¼ï¼ˆproduction ruleï¼‰:
                            ä¾‹å­ï¼š
                                IF åŠ¨ç‰©æœ‰çŠ¬é½¿ AND æœ‰çˆª AND çœ¼ç›¯å‰æ–¹
                                    THEN è¯¥åŠ¨ç‰©æ˜¯é£Ÿè‚‰åŠ¨ç‰©
                                å…¶ä¸­ï¼Œr6æ˜¯è¯¥äº§ç”Ÿå¼çš„ç¼–å·ï¼›â€œåŠ¨ç‰©æœ‰çŠ¬é½¿ AND æœ‰çˆª AND çœ¼ç›¯å‰æ–¹â€æ˜¯äº§ç”Ÿå¼çš„å‰æPï¼›â€œè¯¥åŠ¨ç‰©æ˜¯é£Ÿè‚‰åŠ¨ç‰©â€æ˜¯äº§ç”Ÿå¼çš„ç»“è®ºQã€‚

                        è•´å«å¼ï¼ˆimplication / entailmentï¼‰  
                            ä¾‹å­ï¼š
                                è®¾pã€qä¸ºä¸¤ä¸ªå‘½é¢˜ã€‚å¤åˆå‘½é¢˜"å¦‚æœpï¼Œåˆ™q"ç§°ä¸ºpä¸qçš„è•´å«å¼ï¼Œè®°ä½œpâ†’qã€‚å¹¶ç§°pä¸ºè•´å«å¼çš„å‰ä»¶ï¼Œqä¸ºåä»¶ã€‚å¹¶è§„å®špâ†’qä¸ºå‡å½“ä¸”ä»…å½“pä¸ºçœŸqä¸ºå‡ã€‚
                        æ€»ç»“ï¼š
                            (1) è•´æ¶µå¼è¡¨ç¤ºçš„çŸ¥è¯†åªèƒ½æ˜¯ç²¾ç¡®çš„ï¼Œäº§ç”Ÿå¼è¡¨ç¤ºçš„çŸ¥è¯†å¯ä»¥æ˜¯ä¸ç¡®å®šçš„åŸå› æ˜¯è•´æ¶µå¼æ˜¯ä¸€ä¸ªé€»è¾‘è¡¨è¾¾å¼ï¼Œå…¶é€»è¾‘å€¼åªæœ‰çœŸå’Œå‡ã€‚
                            (2) è•´å«å¼çš„åŒ¹é…ä¸€å®šè¦æ±‚æ˜¯ç²¾ç¡®çš„ï¼Œè€Œäº§ç”Ÿå¼çš„åŒ¹é…å¯ä»¥æ˜¯ä¸ç¡®å®šçš„
        

        gule/mrpc(The Microsoft Research Paraphrase Corpus)   è¯­ä¹‰
            introduction:
                ä»åœ¨çº¿æ–°é—»ä¸­è‡ªåŠ¨æå–å‡ºæ¥çš„å¥å­å¯¹è¯­æ–™åº“ï¼Œäººå·¥æ ‡æ³¨åˆ¤æ–­ä¸¤å¥è¯åœ¨è¯­ä¹‰ä¸Šæ˜¯å¦ç­‰ä»·
                æ¯”å¦‚æ¥è‡ªä¸€æ¡æ–°é—»çš„ä¸€å¥è¯ä»Aåª’ä½“ç™»å‡ºå’Œåœ¨Båª’ä½“ç­‰å¤„å¯èƒ½è¯­ä¹‰ä¸Šç­‰ä»·
            year:2005
            size:1.43 MiB
            format:
                train:3,668  test:1,725 validation 408
                txtæ ¼å¼

                ä¾‹å­ï¼š
                Quality	#1 ID	#2 ID	#1 String	#2 String
                1	702876	702977	Amrozi accused his brother, whom he called "the witness", of deliberately distorting his evidence.	Referring to him as only "the witness", Amrozi accused his brother of deliberately distorting his evidence.
                0	2108705	2108831	Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.	Yucaipa bought Dominick's in 1995 for $693 million and sold it to Safeway for $1.8 billion in 1998.


        

        glue/qqpï¼ˆThe Quora Question Pairs2 datasetï¼‰   è¯­ä¹‰
            introduction:
                    åŒæ ·æ˜¯åˆ¤æ–­å¥å­å¯¹è¯­ä¹‰ç­‰ä»·æ€§ã€‚
                    ç›®çš„ï¼šæŸ¥è¯¢â€œç¾å›½äººå£æœ€å¤šçš„å·æ˜¯ä»€ä¹ˆï¼Ÿâ€ å’Œâ€œç¾å›½å“ªä¸ªå·çš„äººå£æœ€å¤šï¼Ÿâ€ ä¸åº”åœ¨Quoraä¸Šå•ç‹¬å­˜åœ¨ï¼Œå› ä¸ºä¸¤è€…çš„æ„å›¾æ˜¯ç›¸åŒçš„ã€‚æƒ³è¦è‡ªåŠ¨åˆ¤æ–­ä¸¤ä¸ªé—®é¢˜æ˜¯å¦æ˜¯åŒä¸€ä¸ªæ„æ€ã€‚
            year:
            size:57.73 MiB 
            formatï¼š
                tsv
                train: 363,849   test: 390,965   validation:40,430

                æ ¼å¼ä¾‹å­ï¼š
                id	qid1	qid2	question1	question2	is_duplicate
                404285	433578	379845	How many keywords are there in the Racket prog...	How many keywords are there in PERL Programmin...	0
                404286	18840	155606	Do you believe there is life after death?	Is it true that there is life after death?	1
            

        
        
        glue/stsb(The Semantic Textual Similarity Benchmark,è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§åŸºå‡†)       è¯­ä¹‰
            introductionï¼š 
                è¯­ä¹‰æ–‡æœ¬ç›¸ä¼¼æ€§
            year:2017
            size:784.05 KiB
            format:
                csv
                train: 5,749   test: 1,379   validation:1500
                               train  dev test total 
                        -----------------------------
                        news     3299  500  500  4299
                        caption  2000  625  625  3250
                        forum     450  375  254  1079
                        -----------------------------
                        total    5749 1500 1379  8628
                
                ä¾‹å­ï¼š
                    main-captions	MSRvid	2012test	0001	5.000	A plane is taking off.	An air plane is taking off.
                    main-news	headlines	2014	0193	0	Former LAPD officer sought in Irvine slayings	Former CIA officer sentenced to 30 months in prison for info leak
        

        glue/mnli(The Multi-Genre Natural Language Inference Corpu,å¤šç±»è‡ªç„¶è¯­è¨€æ¨ç†è¯­æ–™åº“)    æ¨ç†/è•´å«
        Inference/textual entailmentï¼šæ¨ç†/æ–‡æœ¬è•´å«
        introductionï¼š
            å¤šç±»ï¼šå‰æè¯­å¥æ˜¯ä»åç§ä¸åŒæ¥æºæ”¶é›†çš„ï¼ŒåŒ…æ‹¬è½¬å½•çš„è¯­éŸ³ï¼Œå°è¯´å’Œæ”¿åºœæŠ¥å‘Šã€‚
            ä»»åŠ¡æ˜¯é¢„æµ‹å‰ææ˜¯å¦åŒ…å«å‡è®¾ï¼ˆè•´å«ï¼‰ï¼Œä¸å‡è®¾ç›¸çŸ›ç›¾ï¼ˆçŸ›ç›¾ï¼‰æˆ–ä¸¤è€…éƒ½ä¸ï¼ˆä¸­ç«‹ï¼‰ã€‚
            introductionï¼š
            yearï¼š2017
            sizeï¼š298.29 MiB
            formatï¼š
                jsonlï¼š json linesæ–‡ä»¶ï¼Œ json linesæ–‡ä»¶æ˜¯ä¸€ç§ä¾¿äºå­˜å‚¨ç»“æ„åŒ–æ•°æ®çš„æ ¼å¼ï¼Œå¯ä»¥ä¸€æ¬¡å¤„ç†ä¸€æ¡è®°å½•ã€‚å¯ä»¥ç”¨ä½œæ—¥å¿—æ–‡ä»¶æˆ–è€…å…¶ä»–ã€‚æ¯æ¡jsonæ•°æ®ä¹‹é—´å­˜åœ¨ä¸€ä¸ª"\n"åˆ†éš”ç¬¦ã€‚
            ä¾‹å­ï¼š
                sentence 1:
                    'in that other you know uh that i should do it or that or just to think about doing it rat her than having someone  tell him to do it i know that was a big thing in our house for a long time was that if i wanted my husband to do something to help'
                sentence 1_binary_parse:
                    ( ( ( ( in ( that other ) ) ( you ( know ( uh ( ( that i ) ( should ( do it ) ) ) ) ) ) ) or ) ( ( that ( or ( just ( to ( think ( about ( doing ( it ( ( rat her ) ( than ( having ( someone ( tell ( him ( to ( ( do it ) ( i ( know ( that ( was ( ( a ( big thing ) ) ( in ( ( our house ) ( for ( a ( long time ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ) ( was ( ( that if ) ( i ( wanted ( my ( husband ( to ( do ( ( something to ) help ) ) ) ) ) ) ) ) ) ) )
                sentence 1_parse:
                    (ROOT (SBAR (SBAR (WHPP (IN in) (WHNP (WDT that) (NP (JJ other)))) (S (NP (PRP you)) (VP (VBP know) (SBAR (S (INTJ (UH uh)) (NP (DT that) (FW i)) (VP (MD should) (VP (VB do) (NP (PRP it))))))))) (CC or) (SBAR (WHNP (WDT that)) (PRN (CC or) (ADJP (RB just) (S (VP (TO to) (VP (VB think) (PP (IN about) (S (VP (VBG doing) (S (NP (PRP it)) (VP (VB rat) (NP (PRP her)) (PP (IN than) (S (VP (VBG having) (S (NP (NN someone)) (VP (VB tell) (S (NP (PRP him)) (VP (TO to) (VP (VB do) (NP (PRP it)) (SBAR (S (NP (FW i)) (VP (VBP know) (SBAR (IN that) (S (VP (VBD was) (NP (NP (DT a) (JJ big) (NN thing)) (PP (IN in) (NP (NP (PRP$ our) (NN house)) (PP (IN for) (NP (DT a) (JJ long) (NN time)))))))))))))))))))))))))))))) (S (VP (VBD was) (SBAR (IN that) (IN if) (S (NP (FW i)) (VP (VBD wanted) (NP (PRP$ my) (NN husband) (S (VP (TO to) (VP (VB do) (NP (NN something) (TO to) (VB help))))))))))))))

       
        glue/qnli( The Stanford Question Answering Dataset ,æ–¯å¦ç¦é—®ç­”è¯­æ–™åº“)      é˜…è¯»ç†è§£
            introduction:
                SQuAD 2.0ï¼š æ–¯å¦ç¦æ•´ç†çš„Question & Answer å‹æ•°æ®é›†
                ä»»åŠ¡æ˜¯ç¡®å®šä¸Šä¸‹æ–‡å¥å­æ˜¯å¦åŒ…å«é—®é¢˜çš„ç­”æ¡ˆã€‚ ï¼ˆä»Wikipediaæå–ï¼‰åŒ…å«ç›¸åº”é—®é¢˜çš„ç­”æ¡ˆï¼ˆç”±æ³¨é‡Šè€…ç¼–å†™ï¼‰ã€‚
            year:
            size: 10.14 MiB
            format:  
                Split	Examples
                'test'	5,463
                'train'	104,743
                'validation'	5,463

                json,å…·ä½“ç»“æ„æ•´ç†è§å°æœ¬æœ¬ã€‚

        glue/rte(The Recognizing Textual Entailment (RTE) datasets)
            introductionï¼š
                constructed based on news and Wikipedia text.


        glue/wnliï¼ˆThe Winograd Schema Challenge ï¼‰           é˜…è¯»ç†è§£ï¼Œä¸»è¦ç›®æ ‡æ˜¯è§£å†³ä»£è¯æ¶ˆè§£é—®é¢˜  å¸‚è®®å‘˜æ‹’ç»äº†ç¤ºå¨è€…çš„è®¸å¯è¯ï¼Œå› ä¸ºä»–ä»¬[å®³æ€•/ä¸»å¼ ]æš´åŠ›ã€‚ä»–ä»¬æŒ‡å¾—è°ï¼Ÿ
            introduction:
                æ˜¯ä¸€ä¸ªwinograd schemaçš„é˜…è¯»ç†è§£çš„ä»»åŠ¡ã€‚æœ‰ä»£è¯æ¶ˆè§£é—®é¢˜
                /*/æœ‰ä¸­æ–‡çš„winograd è®­ç»ƒè¯­æ–™åº“

                Winogradæ¨¡å¼
                    Winogradæ¨¡å¼æ˜¯ä¸€å¯¹å¥å­ï¼Œå®ƒä»¬ä¹‹é—´åªæœ‰ä¸€ä¸ªæˆ–ä¸¤ä¸ªè¯ä¸åŒï¼Œå¹¶ä¸”åŒ…å«æ­§ä¹‰ï¼Œè¿™åœ¨ä¸¤ä¸ªå¥å­ä¸­ä»¥ç›¸åçš„æ–¹å¼è§£å†³ï¼Œå¹¶ä¸”éœ€è¦ä½¿ç”¨çŸ¥è¯†åŠå…¶æ¨ç†æ¥è§£å†³ã€‚
                    å¦‚ï¼š Terry Winogradçš„ä¸€ä¸ªè‘—åç¤ºä¾‹

                            å¸‚è®®å‘˜æ‹’ç»äº†ç¤ºå¨è€…çš„è®¸å¯è¯ï¼Œå› ä¸ºä»–ä»¬[å®³æ€•/ä¸»å¼ ]æš´åŠ›ã€‚
                            å¦‚æœ``å®³æ€•''ä¸€è¯ï¼Œåˆ™``ä»–ä»¬''å¤§æ¦‚æ˜¯æŒ‡å¸‚è®®ä¼š; å¦‚æœå®ƒæ˜¯``ä¸»å¼ ''ï¼Œé‚£ä¹ˆ``ä»–ä»¬''å¤§æ¦‚æ˜¯æŒ‡ç¤ºå¨è€…ã€‚
            yearï¼š2011
            sizeï¼š28.32 KiB
            formatï¼š
                Split	Examples
                'test'	146
                'train'	635
                'validation'	71

        glue/axï¼š   æ¨ç†/è•´å«
            introductionï¼š
                æ‰‹åŠ¨ç¼–åˆ¶çš„è¯„ä¼°æ•°æ®é›†ï¼Œç”¨äºå¯¹å„ç§è¯­è¨€ç°è±¡çš„ç³»ç»Ÿæ€§èƒ½è¿›è¡Œç»†ç²’åº¦åˆ†æã€‚ è¯¥æ•°æ®é›†é€šè¿‡è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNLIï¼‰é—®é¢˜ï¼ˆæ–‡æœ¬è•´å«ï¼‰è¯„ä¼°å¥å­çš„ç†è§£èƒ½åŠ›ã€‚ ä½¿ç”¨åœ¨MulitNLIä¸Šè®­ç»ƒçš„æ¨¡å‹ä¸ºè¯¥æ•°æ®é›†ç”Ÿæˆé¢„æµ‹ã€‚
            yearï¼š

            sizeï¼š 217.05 KiB

            formatï¼š(tsv)

                Split	Examples
                'test'	1,104
                åªæœ‰æµ‹è¯•é›†
            ä¾‹å­ï¼š
            
                Lexical Semantics	Predicate-Argument Structure	Logic	Knowledge	Domain	Premise	Hypothesis	Label
                0	NaN	NaN	Negation	NaN	Artificial	The cat sat on the mat.	The cat did not sit on the mat.	contradiction
                1	NaN	NaN	Negation	NaN	Artificial	The cat did not sit on the mat.	The cat sat on the mat.	contradiction
                2	NaN	NaN	Negation	NaN	News	When you've got no snow, it's really hard to l...	When you've got snow, it's really hard to lear...	neutral
                1099	NaN	Active/Passive	NaN	NaN	Artificial	Tunics or shirts of some form or another are w...	People wear tunics or shirts of some form or a...	entailment
----------------------------------------------------------------------------------------------------------------------------------------------------------------
2020/04/20
        SWAG(Inference)   Common Sense çŸ¥è¯†æ¨ç†
            introduction:
                Situations with Adversarial Generationsï¼ˆSWAGï¼‰æ˜¯ä¸€ä¸ªç”±113kå¤šé¡¹é€‰æ‹©é—®é¢˜ç»„æˆçš„æ•°æ®é›†ï¼Œè¿™äº›é—®é¢˜æ¶‰åŠä¸°å¯Œçš„åŸºç¡€æƒ…å¢ƒã€‚
            year:2018
            size:113kä¸ªé—®é¢˜ï¼Œ 80 MiBå·¦å³
            formatï¼šcsv

                ä¾‹å­1:
                ,video-id,fold-ind,startphrase,sent1,sent2,gold-source,ending0,ending1,ending2,ending3,label
                71400	lsmdc3028_GHOST_RIDER_SPIRIT_OF_VENGEANCE-12779	18689	Dropping his gun, a guard races away. Someone	Dropping his gun, a guard races away.	Someone	gen	opens fire with men.	 he flies  .   he was fired   he loves swimming.   0   			
                
                0å·å¥å­ï¼Œå³Someone	gen	opens fire with men.æœ€ç¬¦åˆä¸Šæ–‡æ–‡æ„ã€‚

        Event2Mind (Inference)/*/
            introduction:
                å…³äºäº‹ä»¶ï¼Œæ„å›¾å’Œååº”çš„å¸¸è¯†æ¨æ–­,å¤§å‹è¯­æ–™åº“ï¼ŒåŒ…å«25,000ä¸ªäº‹ä»¶
                ç”¨ä¸€å¥è¯æè¿°ä¸€ä¸ªäº‹ä»¶ï¼Œåˆ†æè¿™å¥è¯æè¿°çš„ä¸¤ä¸ªäººçš„æƒ…ç»ªååº”ã€‚
                ä½œè€…æåˆ°ä¸€ä¸ªåº”ç”¨ï¼šå¯ä»¥é€šè¿‡è®­ç»ƒè¯†åˆ«ç”µå½±ä¸­çš„æ€§åˆ«æ­§è§†è¡Œä¸ºã€‚æˆ‘è®¤ä¸ºå¯ä»¥ç”¨äºASæˆ‘è¦ç ”ç©¶çš„å·¥ä½œã€‚/*/
            year: 2018
            size: 6.44 MiB
            format:csv

                ä¾‹å­ï¼š
                    PersonX puts PersonY in jail.

                    author's annotations:
                        PersonX's intent: ["none", "justice", "to display power"]

                        PersonX's reaction: ["vindicated", "great", "sad", "satisfied"]

                        Other people's reaction: ["sad", "angry", "guilty", "worried", "frustrated"]

                    Source,Event,Xintent,Xemotion,Otheremotion,Xsent,Osent
                    it_events,It starts to rainy,"[""none""]","[""none""]","[""upset""]",,3
                    it_events,It starts to rainy,"[""none""]","[""none""]","[""sad, gloomy""]",,1

                    Xsentï¼Œ Osentè¡¨ç¤ºæƒ…ç»ªååº”ï¼Œä»1åˆ°5è¡¨ç¤ºä»è´Ÿé¢æƒ…ç»ªåˆ°æ­£é¢æƒ…ç»ªã€‚

        Amazon å•†å“è¯„è®ºï¼ˆopinion mining ï¼ŒSAï¼‰
            introductionï¼š
                äºšé©¬é€Šå„ç±»å•†å“çš„è¯„è®ºï¼Œæ•°æ®é‡å¾ˆå¤šï¼ŒGBçº§ã€‚
                yearï¼šupdate at 2018
                size: 100GBå·¦å³
                formatï¼š

                    ä¾‹å­ï¼š
                    reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B
                    asin - ID of the product, e.g. 0000013714
                    reviewerName - name of the reviewer
                    helpful - helpfulness rating of the review, e.g. 2/3
                    reviewText - text of the review
                    overall - rating of the product
                    summary - summary of the review
                    unixReviewTime - time of the review (unix time)
                    reviewTime - time of the review (raw)

                    {
                    "reviewerID": "A2SUAM1J3GNN3B",
                    "asin": "0000013714",
                    "reviewerName": "J. McDonald",
                    "helpful": [2, 3],
                    "reviewText": "I bought this for my husband who plays the piano.  He is having a wonderful time playing these old hymns.  The music  is at times hard to read because we think the book was published for singing from more than playing from.  Great purchase though!",
                    "overall": 5.0,
                    "summary": "Heavenly Highway Hymns",
                    "unixReviewTime": 1252800000,
                    "reviewTime": "09 13, 2009"
                    }



æƒ…æ„Ÿææ€§ï¼š
    è‹±æ–‡ï¼šglue/sst2 å¥å­çº§(BERTåŠå…¶å˜ç§)
    ä¸­æ–‡ï¼š
    https://github.com/SophonPlus/ChineseNlpCorpus
        ChnSentiCorp
            introduction:
                sentence level
                ChnSentiCorp æ˜¯ä¸€ä¸ªä¸­æ–‡æƒ…æ„Ÿåˆ†ææ•°æ®é›†ï¼ŒåŒ…å«é…’åº—ã€ç¬”è®°æœ¬ç”µè„‘å’Œä¹¦ç±çš„ç½‘è´­è¯„è®ºã€‚7000 å¤šæ¡é…’åº—è¯„è®ºæ•°æ®ï¼Œ5000 å¤šæ¡æ­£å‘è¯„è®ºï¼Œ2000 å¤šæ¡è´Ÿå‘è¯„è®ºã€‚
                åªæœ‰0/1ä¸¤ç§æ ‡æ³¨ï¼Œå³æ­£é¢å’Œè´Ÿé¢è¯„ä»·ä¸¤ç§
            year:
            size:1.7 MiB
            format:
                tsv
                ä¸€å¥è¯ä¸€ä¸ªæ ‡æ³¨ï¼ˆ0/1ï¼‰



        waimai
            introduction:
                sentence level
                æŸå¤–å–å¹³å°çš„review,æ­£å‘ 4000 æ¡ï¼Œè´Ÿå‘ çº¦ 8000 æ¡
            yearï¼š
            sizeï¼š0.8 MiB
            formatï¼š
                csv
                åªæœ‰0/1ä¸¤ç§æ ‡æ³¨ï¼Œå³æ­£é¢å’Œè´Ÿé¢è¯„ä»·ä¸¤ç§


        online_shopping_10_cats
            introduction:
                ä¸‹è½½åœ°å€ï¼š 
                æ•°æ®æ¦‚è§ˆï¼š 10 ä¸ªç±»åˆ«ï¼ˆä¹¦ç±ã€å¹³æ¿ã€æ‰‹æœºã€æ°´æœã€æ´—å‘æ°´ã€çƒ­æ°´å™¨ã€è’™ç‰›ã€è¡£æœã€è®¡ç®—æœºã€é…’åº—ï¼‰ï¼Œå…± 6 ä¸‡å¤šæ¡è¯„è®ºæ•°æ®ï¼Œæ­£ã€è´Ÿå‘è¯„è®ºå„çº¦ 3 ä¸‡æ¡
                æ¨èå®éªŒï¼š æƒ…æ„Ÿ/è§‚ç‚¹/è¯„è®º å€¾å‘æ€§åˆ†æ
                æ•°æ®æ¥æºï¼š å„ç”µå•†å¹³å°ï¼Œå…·ä½“ä¸è¯¦
                åŸæ•°æ®é›†ï¼š ä¸­æ–‡æƒ…æ„Ÿåˆ†æè¯­æ–™ã€ä¸­æ–‡æƒ…æ„Ÿåˆ†æè¯­æ–™åº“ï¼Œç½‘ä¸Šæœé›†ï¼Œå…·ä½“ä½œè€…ã€æ¥æºä¸è¯¦
                åŠ å·¥å¤„ç†ï¼š
                å°† 2 ä»½è¯­æ–™æ•´åˆæˆ 1 ä»½è¯­æ–™
                å°†åŸæ¥é›¶æ•£çš„ excel, txt æ–‡æ¡£ï¼Œæ•´åˆæˆ 1 ä¸ª ç»Ÿä¸€çš„ csv æ–‡æ¡£
                å»é‡
            year:
            size:4 MiB
            format:
                csv
                æ¯”ä¸Šé¢ä¸¤ä¸ªæ•°æ®é›†å¤šäº†åˆ†ç±»æ ‡ç­¾ï¼Œå¦‚ä¹¦ç±ã€æ°´æœã€æ‰‹æœºç­‰ï¼Œå…±æœ‰3ä¸ªæ ‡ç­¾ã€‚


        weibo_senti_100k
            introduction:
                æ•°æ®æ¦‚è§ˆï¼š 10 ä¸‡å¤šæ¡ï¼Œå¸¦æƒ…æ„Ÿæ ‡æ³¨ æ–°æµªå¾®åšï¼Œæ­£è´Ÿå‘è¯„è®ºçº¦å„ 5 ä¸‡æ¡
                æ¨èå®éªŒï¼š æƒ…æ„Ÿ/è§‚ç‚¹/è¯„è®º å€¾å‘æ€§åˆ†æ
                æ•°æ®æ¥æºï¼š æ–°æµªå¾®åš
                åŸæ•°æ®é›†ï¼š æ–°æµªå¾®åšï¼Œæƒ…æ„Ÿåˆ†ææ ‡è®°è¯­æ–™å…±12ä¸‡æ¡ï¼Œç½‘ä¸Šæœé›†ï¼Œå…·ä½“ä½œè€…ã€æ¥æºä¸è¯¦
                åŠ å·¥å¤„ç†ï¼š
                å°†åŸæ¥çš„ 2 ä»½æ–‡æ¡£ï¼Œæ•´åˆæˆ 1 ä»½ csv æ–‡ä»¶
                ç¼–ç ç»Ÿä¸€ä¸º UTF-8
                å»é‡
            year:
            size:9.15 MiB
            format:
                csv
                ä¸¤ä¸ªæ ‡ç­¾ï¼šæ–‡æœ¬+åˆ†ç±»ï¼ˆ0/1ï¼‰
        
        




-----------------------------------------------------------------------
ä¼ä¸šç•Œç°çŠ¶ï¼š











æ¯”èµ›èƒ½è¾¾åˆ°çš„å‡†ç¡®ç‡ï¼š
    æ¯”èµ›1ï¼š
        æœ‰æ— codeï¼š

    æ¯”èµ›2ï¼š
        æœ‰æ— codeï¼š



-----------------------------------------------------------------------
    åŸºäºhttps://github.com/niderhoff/nlp-datasetsæ•´ç†äº†è‹±æ–‡æ•°æ®é›†






-------------------------------------------------------------------------------------------------------------------------------------------------
HMMï¼ˆéšé©¬å°”ç§‘å¤«æ¨¡å‹ï¼‰   ------->   CRF(æ¡ä»¶éšå³åœº)

HMM
    éšå³è¿‡ç¨‹å’Œéšæœºå˜é‡
        éšæœºè¿‡ç¨‹ï¼Œå¦‚è‚¡ç¥¨çš„èµ°åŠ¿ï¼Œè‚¡ç¥¨ä»·æ ¼æœ¬èº«æ˜¯ä¸ªæœªçŸ¥çš„ï¼Œä½†æ˜¯t+1æ—¶åˆ»çš„ä»·æ ¼å’Œtæ—¶åˆ»çš„ä»·æ ¼æœ‰å…³ç³»ï¼Œè¿™æ°æ°æ˜¯äººä»¬æ„Ÿå…´è¶£çš„ã€‚æ•´ä¸ªè¿‡ç¨‹æ˜¯éšæœºçš„ï¼Œä½†è¿‡ç¨‹ä¹‹ä¸­çš„ç›¸é‚»ç‚¹å´æ˜¯ç›¸å…³çš„ã€‚  å½“ç„¶ï¼Œéšæœºè¿‡ç¨‹çš„çŠ¶æ€åº¦é‡ä¸ä¸€å®šæ˜¯æ—¶é—´tï¼Œè¿˜å¯ä»¥æ˜¯å„ç§â€œpathâ€ã€‚
        ä»¥å¾€éšæœºå˜é‡ä¹‹é—´éƒ½æ˜¯ä¸ç›¸å…³çš„ï¼Œè¿™ä½“ç°äº†è¿›æ­¥ã€‚
        å‚è€ƒï¼šhttps://www.zhihu.com/question/280948058

    ç‹¬ç«‹æ€§è¾“å‡ºå‡è®¾ï¼š
        
        P(o1,o2,o3,...|s1,s2,s3....)=P(o1|s1)*P(o2|s2)*P(o3|s3)...  ä»æ„ä¹‰ä¸Šç†è§£å®ƒçš„å®šä¹‰äº†ï¼Œå…¬å¼ä¸Šä¸å¥½æ¨


CRF 
    A CRF can be considered as a generalization of HMM or we can say that a HMM is a particular case of CRF where constant probabilities are used to model state transitions.
    åˆ¤åˆ«å¼æ¨¡å‹
        åˆ¤åˆ«å¼æ¨¡å‹ discriminative model è®¡ç®—æ¡ä»¶æ¦‚ç‡ï¼Œ
            ç»™å‡ºxé¢„æµ‹y
        è€Œç”Ÿæˆå¼æ¨¡å‹ generative model è®¡ç®—è”åˆæ¦‚ç‡åˆ†å¸ƒã€‚
            ç»™å‡ºPï¼ˆxï¼Œyï¼‰å’Œxï¼Œæ±‚ä½¿Pï¼ˆxï¼Œ yï¼‰æœ€å¤§çš„y
    It has been observed that CRF-based learning method was more suitable for mining aspects, opinions and intensifiers (including phrases) in comparison to LHMMs based and statistical methods. 


    The task of assigning labels to a set of observation sequences arises in many fields, 

    åœ¨å¾ˆå¤šåº”ç”¨é‡Œï¼Œæˆ‘ä»¬éƒ½å¸Œæœ›èƒ½å¤Ÿé¢„æµ‹ç›¸äº’å…³è”çš„å¤šä¸ªå˜é‡ã€‚å¦‚ä¸€ä¸ªsports teamçš„æ¯”èµ›è¡¨ç°å’Œæ¯ä½é˜Ÿå‘˜çš„å¥åº·çŠ¶å†µæœ‰å…³ï¼Œè€Œé˜Ÿå‘˜çš„å¥åº·çŠ¶å†µå’Œteamçš„æ¯”èµ›å¯†åº¦å®‰æ’å’Œè¡Œç¨‹åŠ³é¡¿ç¨‹åº¦æœ‰å…³ã€‚æ¯”èµ›ç»“æœè¿˜å’Œå£«æ°”æœ‰å…³ï¼Œè€Œå£«æ°”åˆåè¿‡æ¥å½±å“å¥åº·çŠ¶å†µã€‚

    å¯ä»¥çœ‹å‡ºï¼Œå¤šä¸ªå˜é‡å½¼æ­¤å†…éƒ¨ç›¸å…³è”ã€‚ç”¨CRFæ¡ä»¶éšæœºåœºæ¥è§£å†³æ­¤ç±»é—®é¢˜éå¸¸æœ‰æ•ˆã€‚
    æœ‰è®¸å¤šç±»ä¼¼åº”ç”¨ï¼Œ å¦‚æŠ½å–NLPå¥æ³•ï¼Œå›¾ç‰‡åŒºåŸŸçš„åˆ’åˆ†ï¼ŒDNAé“¾çš„åˆ’åˆ†ã€‚

    åœ¨è¿™äº›åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¸Œæœ›æ ¹æ®è§‚æµ‹åˆ°çš„ç‰¹å¾çŸ¢é‡ï¼Œæ¥é¢„æµ‹ä¸€äº›éšæœºå˜é‡ã€‚

    1. graphical model
        graphical modelæ˜¯è¡¨ç¤ºè¿™ç§ç›¸äº’ä¹‹é—´å…³ç³»çš„ä¸€ä¸ªè‡ªç„¶çš„åšæ³•ã€‚graphical model åŒ…æ‹¬Bayesian ç½‘ç»œï¼Œç¥ç»ç½‘ç»œï¼Œfactor graphsï¼Œé©¬å°”ç§‘å¤«éšæœºåœºç­‰ç­‰ã€‚ 
    
    2. ä¸ºä»€ä¹ˆåªæœ‰æœ‰graphical modelä¸å¤Ÿï¼Ÿ  -----è¦åˆ ç¹å°±ç®€
        å¤§å¤šæ•°NLPçš„åº”ç”¨éƒ½æœŸæœ›å¾—åˆ°è”åˆæ¦‚ç‡åˆ†å¸ƒï¼Œä¹Ÿå°±æ˜¯å¾—åˆ°ç”Ÿæˆæ¨¡å‹ã€‚
        A generative model is a model for randomly generating observable data based on given parameters. 
        ç”Ÿæˆæ¨¡å‹è™½ç„¶æœ‰ç§ç§å¥½å¤„ï¼Œä½†æ˜¯ä¹Ÿæœ‰ä¸å°‘å¼Šç«¯ï¼Œå¦‚è¾“å…¥æ•°æ®çš„ç»´åº¦ä¸€èˆ¬å¾ˆå¤§ï¼Œå¹¶ä¸”ç‰¹å¾ä¹‹é—´æœ‰å¾ˆå¤æ‚çš„ä¾èµ–å…³ç³»ï¼Œæ‰€ä»¥æ ¹æ®è¿™ä¸¤è€…æ„å»ºä¸€ä¸ªæ¦‚ç‡æ¨¡å‹å¾ˆéš¾ï¼Œå³ä¾¿çœŸçš„æ„å»ºå‡ºæ¥ä¹Ÿä¼šå¾ˆå¤æ‚ï¼Œå¾ˆå¯èƒ½è¿‡æ‹Ÿåˆã€‚

        æ‰€ä»¥ä¸å¦‚æˆ‘ä»¬éƒ¨åˆ†å¿½ç•¥è¿™äº›ä¾èµ–ï¼ŒCRFåªè€ƒè™‘è¾“å…¥ä¸´è¿‘çš„æ•°æ®ï¼Ÿ
            å¦‚ç”¨ç±³é¥­åœ¨ç›˜å­ä¸ŠçŒœä¸€ä¸ªèœè‚´ï¼Œæˆ‘ä»¬å¾ˆéš¾çŒœï¼Œå› ä¸ºè¿™æ ·çš„ä¾‹å­å¤ªå¤šäº†ã€‚å¦‚æœå‘Šè¯‰ä½ ä»–æ—è¾¹æœ‰æ‰¬å·é¢æ¡ï¼Œæ‰¬å·çƒ¤é¸­ï¼Œæ‰¬å·é‡Œè„Šï¼Œä½ å¯èƒ½å°±èƒ½çŒœå‡ºè¿™æ˜¯æ‰¬å·ç‚’é¥­äº†ã€‚è¿™å°±æ˜¯CRFçš„åŸç†ã€‚è‡³äºæ¡Œå­å› è¿™ä¸ªèœä¸‹æ²‰äº†å‡ å¾®ç±³ï¼Œç©ºæ°”æµåŠ¨å› ä¸ºè¿™ä¸ªèœæ”¶åˆ°äº†ä»€ä¹ˆå½±å“å°±ä¸å»ç®¡äº†ã€‚

            HMMå°±æ˜¯å¿½ç•¥çš„å¤ªå¤šäº†ï¼Œåªåˆ©ç”¨äº†ç±³é¥­å’Œç›˜å­è¿™ä¸€ä¸ªç›¸å…³ä¿¡æ¯ï¼Œæ²¡æœ‰åˆ©ç”¨ä¸´è¿‘ä¿¡æ¯ã€‚
---------------------------------------------------------------------------
    CRFå¦‚ä½•è§£å†³graphical modelsé¢ä¸´çš„é—®é¢˜ï¼Ÿ  ï¼ˆCRFä¹Ÿæ˜¯ä¸€ç§graphical modelï¼‰
        ä¸€ç§è§£å†³æ–¹æ³•æ˜¯ç›´æ¥å°†æ¡ä»¶åˆ†å¸ƒmodelå‡ºæ¥ï¼Œå¯¹äºåˆ†ç±»é—®é¢˜æ¥è¯´è¿™å°±æ˜¯æ‰€éœ€çš„å…¨éƒ¨äº†ã€‚/ï¼Ÿ/
        CRFæœ¬è´¨ä¸Šæ˜¯å°†classificationå’Œgraphical modelingçš„ä¼˜åŠ¿ç»“åˆåœ¨ä¸€èµ·ã€‚å°†åˆ©ç”¨å¤§é‡æ•°æ®è¿›è¡Œé¢„æµ‹å’Œåˆ©ç”¨compactly å¤šå˜é‡æ•°æ®å»ºæ¨¡çš„ä¼˜åŠ¿ç»“åˆèµ·æ¥ã€‚
        
        /ï¼Ÿ/ä»æŸç§è§’åº¦æ¥è¯´ï¼Œç”Ÿæˆæ¨¡å‹å’ŒCRFçš„å…³ç³»å¯ä»¥ç±»æ¯”äºæœ´ç´ è´å¶æ–¯å’Œé€»è¾‘å›å½’åˆ†ç±»ã€‚
        /ï¼Ÿ/å…¶å®å¤šé¡¹å¼é€»è¾‘å›å½’æ¨¡å‹å¯ä»¥è¢«çœ‹ä½œæœ€ç®€å•çš„ä¸€ç§CRF--åªæœ‰ä¸€ä¸ªè¾“å‡ºå˜é‡ã€‚
        /*/ å¡«å‘ï¼šæœ´ç´ è´å¶æ–¯   é€»è¾‘å›å½’

    
    æ‰€ä»¥ç©¶ç«Ÿä»€ä¹ˆæ˜¯CRFï¼Ÿ
        ç”¨æ¥åˆ†ç±»å’Œsegmenting ç»“æ„æ•°æ®ï¼Œå¦‚åºåˆ—ï¼Œæ ‘å’Œlatticeã€‚CRFå°¤å…¶é€‚åˆäºå¯¹æ—¶åºæ•°æ®è¿›è¡Œå»ºæ¨¡ï¼ˆå› ä¸ºæ—¶é—´ä¾èµ–å¯ä»¥é€šè¿‡å„ç§ä¸åŒçš„æ–¹å¼è¡¨è¾¾ï¼‰ï¼ŒThe underlying idea is that of defining a conditional probability distribution over label sequences given a particular observation sequence, rather than a joint distribution over both label and observation sequences. 

        CRFçš„ä¸»è¦ä¼˜åŠ¿æ˜¯æ”¾å®½ç‹¬ç«‹å‡è®¾ï¼ˆthe variables donâ€™t depend on each other and they donâ€™t affect each other in any wayï¼‰å–å¾—çš„ã€‚
    
    HMM vs CRF  /?/
        HMM is a generative model and it gives the output directly by modeling the transition matrix based on the training data. The results can be improved by providing more datapoints, but there is no direct control over the output labels. HMM learns the transition probabilities on its own based on the training data provided. Hence if we provide more datapoints, then we can improve the model to include wider variety. CRF is a discriminative model which outputs a confidence measure. This is really useful in most cases because we want to know how sure the model is about the label at that point. This confidence measure can be thresholded to suit various applications. The good thing about confidence measure is that the number of false alarms is low compared to HMM.

        The primary advantage of CRFs over HMMs is their conditional nature, resulting in the relaxation of the independence assumptions required by HMMs. Additionally, CRFs avoid the label bias problem, a weakness exhibited by Markov models based on directed graphical models.
        /*/ A CRF can be considered as a generalization of HMM or we can say that a HMM is a particular case of CRF where constant probabilities are used to model state transitions. CRFs outperform HMMs on a number of real-world sequence labeling tasks.

        /ï¼Ÿ/å¡«å‘ï¼šHMMçš„ï¼šlabel bias problemï¼ˆæœ‰å‘å›¾çš„å¤©ç”Ÿä¸è¶³ï¼Œæ— å‘å›¾å¦‚CRFæ— æ­¤ç¼ºç‚¹ï¼‰

        There are many libraries available out there like HCRF, CRFall, CRF++ etc, that have CRF functionalities nicely defined and implemented. You can check them out and see how they work out for your project.

    

---------------------------------------------------------------------------
https://towardsdatascience.com/implementing-a-linear-chain-conditional-random-field-crf-in-pytorch-16b0b9c4b4ea

code implement for CRF  
    Over the last few years, CRFs models were combined with LSTMs to get state-of-the-art results. In the NLP community this was considered a rule of thumb for sequence tagging: if you want more accuracy just stack a CRF on top of your LSTM layer and bang â­ï¸! You can see some examples here or here.

    In a sequence classification problem, our final objective is to find the probability of a sequence of labels (y) given an input of sequence vectors (X). This is denoted as P(y | X).

    å›¾1ï¼šhttps://app.yinxiang.com/Home.action#n=b36da91d-e2b6-44ae-9a65-ca2d96928dcb&s=s47&ses=4&sh=5&sds=2&x=crf&
    These are some intuitions of why we use exp:
        Underflow: When we multiply very small numbers, we get a smaller number which may suffer underflow.
        Non-negative outputs: All values are mapped between 0 and +inf.
        Monotonically increasing: It pushes high values up and low values down. This has a similar effect with an argmax operation. More here.

    Now we are going to add new learnable weights to model the chance of a label yk being followed by yk+1. By modelling this, we are creating a dependency between successive labels! Thus, the name linear-chain CRF! In order to do so, we multiply our previous probability by P(yk+1 | yk), for which we can use exponential properties to rewrite it as unary scores U(x, y) plus learnable transition scores T(y, y):
    å›¾2ï¼šhttps://app.yinxiang.com/Home.action#n=b36da91d-e2b6-44ae-9a65-ca2d96928dcb&s=s47&ses=4&sh=5&sds=2&x=crf&


    å›¾3ï¼šhttps://app.yinxiang.com/Home.action#n=b36da91d-e2b6-44ae-9a65-ca2d96928dcb&s=s47&ses=4&sh=5&sds=2&x=crf&
    Turns out itâ€™s not trivial to compute Z(X) because we have too many nested loops ğŸ˜–! Itâ€™s a sum over all possible combinations over the label set at each timestep. To be more precise, we have â„“ computations over the label set. This give us a time complexity of O(|y|^â„“).
    
    Luckily, we can exploit the recurrent dependencies and use dynamic programmingï¼ˆåŠ¨æ€è§„åˆ’ï¼‰ to compute it efficiently ğŸ˜! The algorithm that does this is called forward algorithm or backward algorithm â€” depending on the order that you iterate over the sequence.






    




